{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77738df5-e62c-4bf9-ba20-baffea46e951",
   "metadata": {},
   "source": [
    "This notebook shows how to use LLM-Geo, you can uncomment a study case (preferred Case 1 and Case 3) to get the spatial analysis results without any human intervention. \n",
    "\n",
    "Please check the [webpage of LLM-Geo](https://github.com/gladcolor/LLM-Geo) for more detail!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf676855-2221-47c7-8dff-b185e03c3953",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Install package\n",
    "\n",
    "Make sure you are using the latest version of `openai` and `geopandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05156c09-3ec8-47d7-a629-f9374440658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install pyvis\n",
    "# ! pip install networkx\n",
    "# ! pip install openai\n",
    "# ! conda update  --channel conda-forge geopandas  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254e9bd-675a-4644-abfd-d642183da809",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392efdfe-e33d-43fb-b8ea-6b6fb444ad9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pyvis.network import Network\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML, Code\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43a82-d40f-4442-93fb-525486017ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Solution class\n",
    "Please run the following cell to define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236eff8d-4f24-4e90-af5f-4847bf2e7112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import LLM_Geo_Constants as constants\n",
    "import helper\n",
    "\n",
    "from LLM_Geo_kernel import Solution\n",
    "\n",
    "sys.path.append(os.path.abspath(\"Modules\"))    \n",
    "import Modules.data_eye as data_eye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e84cf-00f5-40ef-a7ff-5ae186a4e164",
   "metadata": {},
   "source": [
    "# Demonstration Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a545a6b-1456-40b8-a913-b4dfd305c071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input task and data desciption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd66b2f3-80d7-40bb-9fd0-807a3f70e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "isReview = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba05f98-30b2-46d0-9eb2-624f5dbc2754",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Case 1: population living near hazardous wastes\n",
    "\n",
    "# task_name ='Resident_at_risk_counting'\n",
    "# TASK = r\"\"\"1) Find out Census tracts that contain hazardous waste facilities, then comppute and print out the population living in those tracts. The study area is North Carolina (NC), US.\n",
    "# 2) Generate a population choropleth map for all tract polygons in NC, rendering the color by tract population; and then highlight the borders of tracts that have hazardous waste facilities. Please draw all polygons, not only the highlighted ones. The map size is 15*10 inches.\n",
    "# \"\"\"\n",
    "\n",
    "# data location with column information\n",
    "# DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip.\",\n",
    "#                   \"NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip. The tract ID column is 'GEOID', data types is integer.\",\n",
    "#                   \"NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. The population is stored in 'TotalPopulation' column. The tract ID column is 'GEOID', data types is integer.\"\n",
    "#                  ]\n",
    "\n",
    "# data location without column information\n",
    "# DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip.\",\n",
    "#                   \"NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip.\",\n",
    "#                   \"NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv.\"\n",
    "#                  ]\n",
    " \n",
    "\n",
    "# # Case 3: COVID-19 death rate in US\n",
    "# task_name ='COVID_death_rate'\n",
    "# TASK = r'''1) Draw a choropleth map to show the death rate (death/case) of COVID-19 among the countiguous US counties. Use the accumulated COVID-19 data of 2020.12.31 to compute the death rate. Use scheme ='quantiles' when plotting the map.  Set map projection to 'Conus Albers'. Set map size to 15*10 inches.  \n",
    "# 2) Draw a scatter plot to show the correlation and trend line of the death rate with the senior resident rate, including the r-square and p-value. Set data point transparency to 50%, regression line as red. Set figure size to 15*10 inches.  \n",
    "# '''\n",
    "\n",
    "# data location with column information\n",
    "# DATA_LOCATIONS = [\n",
    "#                   r\"COVID-19 data case in 2020 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv. This data is for daily accumulated COVID cases and deaths for each county in the US. There are 5 columns: date (format: 2021-02-01), county, state, fips, cases, deaths. \",   \n",
    "#                   r\"Contiguous US county boundary (ESRI shapefile): https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip. The county FIPS column is 'GEOID'; map projection is EPSG:4269\",\n",
    "#                   r\"Census data (ACS2020): https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county.csv. THe needed columns are: 'FIPS', 'Total Population', 'Total Population: 65 to 74 Years', 'Total Population: 75 to 84 Years', 'Total Population: 85 Years and Over'. Drop rows with NaN cells after loading the used columns.\",\n",
    "#                  ]\n",
    "\n",
    "# data location without column information\n",
    "# DATA_LOCATIONS = [\n",
    "#                   r\"COVID-19 data case in 2020 (county-level): https://github.com/nytimes/covid-19-data/raw/master/us-counties-2020.csv. This data is for daily accumulated COVID cases and deaths for each county in the US. \",   \n",
    "#                   r\"Contiguous US county boundary (ESRI shapefile): https://github.com/gladcolor/spatial_data/raw/master/contiguous_counties.zip.\",\n",
    "#                   r\"Census data (ACS2020): https://raw.githubusercontent.com/gladcolor/spatial_data/master/Demography/ACS2020_5year_county.csv. \"\n",
    "#                  ]\n",
    "\n",
    "# # Case 4: Hospital_accessibility\n",
    "# task_name ='Hospital_accessibility'\n",
    "# TASK = r'''\n",
    "# For each zipcode area in South Carolina (SC), calculate the distance from the centroid of the zipcode area to its nearest hospital, and then create a choropleth distance map of zipcode area polygons (unit: km), also show the hospital.\n",
    "# '''\n",
    "\n",
    "## data location with column information\n",
    "# DATA_LOCATIONS = [\n",
    "# r\"SC zipcode boundary shapefile: https://github.com/GIBDUSC/test/raw/master/sc_zip_boundary.zip, the map projection is WGS1984.\",\n",
    "# r\"SC hospitals:  https://github.com/gladcolor/spatial_data/raw/master/South_Carolina/SC_hospitals_with_emergency_room_cleaned.csv, location columns: longitude in 'Longitude' column, latitude in 'Latitude' column.\",          \n",
    "# ]\n",
    "\n",
    "# data location without column information\n",
    "# DATA_LOCATIONS = [\n",
    "# r\"SC zipcode boundary shapefile: https://github.com/GIBDUSC/test/raw/master/sc_zip_boundary.zip.\",\n",
    "# r\"SC hospitals:  https://github.com/gladcolor/spatial_data/raw/master/South_Carolina/SC_hospitals_with_emergency_room_cleaned.csv.\",          \n",
    "# ]\n",
    "\n",
    "# Case 5: Census API\n",
    "\n",
    "\n",
    "\n",
    "# # Case 2: France_mobility_changes_2020  (NOTE: invalidated due to API shutdown)\n",
    "# task_name ='France_mobility_changes_2020'\n",
    "# TASK = r'''\n",
    "# 1) Show the 2020 human mobility monthly change rates of each administrative regions in a France choropleth map. Each month is a sub-map in a map matrixï¼Œ12 months in total. All monthly maps need to use the same colorbar range (color scheme: coolwarm). The base of the change rate is January 2020. \n",
    "# 2) Draw a line chart to show the monthly change rate trends of all administrative regeions. Each region is a line (the region name is the legend), the x-axis is 2020 months.\n",
    "# '''\n",
    "\n",
    "# DATA_LOCATIONS = [\"ESRI shapefile for France administrative regions:\" + \\\n",
    "#                   \"https://github.com/gladcolor/LLM-Geo/raw/master/REST_API/France.zip. \" + \\\n",
    "#                   \"The 'GID_1' column is the administrative region code, 'NAME_1' column is the administrative region name.\",\n",
    "#                   \"REST API url with parameters for daily human mobility data access:\" + \\\n",
    "#                   \"http://gis.cas.sc.edu/GeoAnalytics/REST?operation=get_daily_movement_for_all_places&source=twitter&scale=world_first_level_admin&begin=01/01/2020&end=12/31/2020.\" + \\\n",
    "#                   \"The response is in CSV format. There are three columns in the response: \" + \\\n",
    "#                   \"place,date (format:2020-01-07), and intra_movement. 'place' column is the administractive region code of every country;\" + \\\n",
    "#                   \"codes for France administrative regions start with 'FRA'. Use the total intra_movement of the month as the montly mobility.\",\n",
    "#                  ]\n",
    "\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), task_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# create graph\n",
    "model = r'gpt-4o'\n",
    "model = r'gpt-4o-2024-08-06'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1af76a-4fb7-42fe-a9a7-99c345806084",
   "metadata": {},
   "source": [
    "## Get data overview (column names, data types, and map projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae1f0af-5ee3-4e92-8283-fedc594dff42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_LOCATIONS with data overviews:\n",
      "['You can use the US Census Bureau API.You can use the US Census Bureau API. Data overview: ']\n"
     ]
    }
   ],
   "source": [
    "attributes_json, DATA_LOCATIONS = data_eye.add_data_overview_to_data_location(task=TASK, data_location_list=DATA_LOCATIONS, model=model)\n",
    "print(\"DATA_LOCATIONS with data overviews:\")\n",
    "print(DATA_LOCATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2bf945-5de9-4512-b9bb-89d4082b1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt to get solution graph:\n",
      "\n",
      "Your role: A professional Geo-information scientist and programmer good at Python. You have worked on Geographic information science more than 20 years, and know every detail and pitfall when processing spatial data and coding. You know well how to set up workflows for spatial analysis tasks. You have significant experence on graph theory, application, and implementation. You are also experienced on generating map using Matplotlib and GeoPandas.\n",
      " \n",
      "\n",
      "Your task: Generate a graph (data structure) only, whose nodes are (1) a series of consecutive steps and (2) data to solve this question:  \n",
      "  Show the spatial distribution of the county level median income in the contigous US. Set figure size to (25,15)\n",
      " \n",
      "\n",
      "Your reply needs to meet these requirements: \n",
      " 1. Think step by step.\n",
      "2. Steps and data (both input and output) form a graph stored in NetworkX. Disconnected components are NOT allowed.\n",
      "3. Each step is a data process operation: the input can be data paths or variables, and the output can be data paths or variables.\n",
      "4. There are two types of nodes: a) operation node, and b) data node (both input and output data). These nodes are also input nodes for the next operation node.\n",
      "5. The input of each operation is the output of the previous operations, except the those need to load data from a path or need to collect data.\n",
      "6. You need to carefully name the output data node, making they human readable but not to long.\n",
      "7. The data and operation form a graph.\n",
      "8. The first operations are data loading or collection, and the output of the last operation is the final answer to the task.Operation nodes need to connect via output data nodes, DO NOT connect the operation node directly.\n",
      "9. The node attributes include: 1) node_type (data or operation), 2) data_path (data node only, set to \"\" if not given ), and description. E.g., {\"name\": \"County boundary\", \"data_type\": \"data\", \"data_path\": \"D:\\Test\\county.shp\",  \"description\": \"County boundary for the study area\"}.\n",
      "10. The connection between a node and an operation node is an edge.\n",
      "11. Add all nodes and edges, including node attributes to a NetworkX instance, DO NOT change the attribute names.\n",
      "12. DO NOT generate code to implement the steps.\n",
      "13. Join the attribute to the vector layer via a common attribute if necessary.\n",
      "14. Put your reply into a Python code block, NO explanation or conversation outside the code block(enclosed by ```python and ```).\n",
      "15. Note that GraphML writer does not support class dict or list as data values.\n",
      "16. You need spatial data (e.g., vector or raster) to make a map.\n",
      "17. Do not put the GraphML writing process as a step in the graph.\n",
      "18. Keep the graph concise, DO NOT use too many operation nodes.\n",
      "19. Save the network into GraphML format, save it at: D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\Python_code\\Census_API\\Census_API.graphml \n",
      "\n",
      "Your reply example: \n",
      "```python\n",
      "import networkx as nx\n",
      "G = nx.DiGraph()\n",
      "# Add nodes and edges for the graph\n",
      "# 1 Load hazardous waste site shapefile\n",
      "G.add_node(\"haz_waste_shp_url\", node_type=\"data\", path=\"https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/Hazardous_Waste_Sites.zip\", description=\"Hazardous waste facility shapefile URL\")\n",
      "G.add_node(\"load_haz_waste_shp\", node_type=\"operation\", description=\"Load hazardous waste facility shapefile\")\n",
      "G.add_edge(\"haz_waste_shp_url\", \"load_haz_waste_shp\")\n",
      "G.add_node(\"haz_waste_gdf\", node_type=\"data\", description=\"Hazardous waste facility GeoDataFrame\")\n",
      "G.add_edge(\"load_haz_waste_shp\", \"haz_waste_gdf\")\n",
      "...\n",
      "```\n",
      " \n",
      "\n",
      "Data locations (each data is a node): 1. You can use the US Census Bureau API.You can use the US Census Bureau API. Data overview:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "solution = Solution(\n",
    "                    task=TASK,\n",
    "                    task_name=task_name,\n",
    "                    save_dir=save_dir,\n",
    "                    data_locations=DATA_LOCATIONS,\n",
    "                    model=model,\n",
    "                    )\n",
    "print(\"Prompt to get solution graph:\\n\")\n",
    "print(solution.graph_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009da7e-afe7-48da-a0c0-62d5a10026fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get graph code from GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "213b17ca-9e3e-4c23-a852-c4a7edc83448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">networkx</span> <span class=\"k\">as</span> <span class=\"nn\">nx</span>\n",
       "\n",
       "<span class=\"n\">G</span> <span class=\"o\">=</span> <span class=\"n\">nx</span><span class=\"o\">.</span><span class=\"n\">DiGraph</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"c1\"># 1. Load county boundary shapefile for the contiguous US</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;county_shp_path&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;data&quot;</span><span class=\"p\">,</span> <span class=\"n\">data_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;path/to/contiguous_us_county_shapefile.shp&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Path to the county boundary shapefile for the contiguous US&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;load_county_boundary&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;operation&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Load county boundary shapefile into GeoDataFrame&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;county_shp_path&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;load_county_boundary&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;county_boundary_gdf&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;data&quot;</span><span class=\"p\">,</span> <span class=\"n\">data_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;County boundary GeoDataFrame&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;load_county_boundary&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;county_boundary_gdf&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># 2. Collect median income data through US Census Bureau API</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;median_income_api_url&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;data&quot;</span><span class=\"p\">,</span> <span class=\"n\">data_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;US Census Bureau API URL for county level median income&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;collect_income_data&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;operation&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Collect median income data using the Census API&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;median_income_api_url&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;collect_income_data&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;median_income_data&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;data&quot;</span><span class=\"p\">,</span> <span class=\"n\">data_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Median income data collected&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;collect_income_data&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;median_income_data&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># 3. Join median income data to the county boundaries</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;join_income_to_boundary&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;operation&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Join median income data to county boundary GeoDataFrame on a common attribute&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;median_income_data&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;join_income_to_boundary&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;county_boundary_gdf&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;join_income_to_boundary&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;county_income_gdf&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;data&quot;</span><span class=\"p\">,</span> <span class=\"n\">data_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;County boundary GeoDataFrame with median income data&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;join_income_to_boundary&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;county_income_gdf&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># 4. Generate map to show spatial distribution of median income</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;generate_income_map&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;operation&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Generate a map showing the spatial distribution of median income at the county level&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;county_income_gdf&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;generate_income_map&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_node</span><span class=\"p\">(</span><span class=\"s2\">&quot;income_distribution_map&quot;</span><span class=\"p\">,</span> <span class=\"n\">node_type</span><span class=\"o\">=</span><span class=\"s2\">&quot;data&quot;</span><span class=\"p\">,</span> <span class=\"n\">data_path</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;</span><span class=\"p\">,</span> <span class=\"n\">description</span><span class=\"o\">=</span><span class=\"s2\">&quot;Map showing spatial distribution of county level median income&quot;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">G</span><span class=\"o\">.</span><span class=\"n\">add_edge</span><span class=\"p\">(</span><span class=\"s2\">&quot;generate_income_map&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;income_distribution_map&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Save the graph to a GraphML file</span>\n",
       "<span class=\"n\">nx</span><span class=\"o\">.</span><span class=\"n\">write_graphml</span><span class=\"p\">(</span><span class=\"n\">G</span><span class=\"p\">,</span> <span class=\"s2\">&quot;D:</span><span class=\"se\">\\\\</span><span class=\"s2\">OneDrive_PSU</span><span class=\"se\">\\\\</span><span class=\"s2\">OneDrive - The Pennsylvania State University</span><span class=\"se\">\\\\</span><span class=\"s2\">Research_doc</span><span class=\"se\">\\\\</span><span class=\"s2\">LLM_Geo</span><span class=\"se\">\\\\</span><span class=\"s2\">Python_code</span><span class=\"se\">\\\\</span><span class=\"s2\">Census_API</span><span class=\"se\">\\\\</span><span class=\"s2\">Census_API.graphml&quot;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{networkx} \\PY{k}{as} \\PY{n+nn}{nx}\n",
       "\n",
       "\\PY{n}{G} \\PY{o}{=} \\PY{n}{nx}\\PY{o}{.}\\PY{n}{DiGraph}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} 1. Load county boundary shapefile for the contiguous US}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}shp\\PYZus{}path}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{data\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{path/to/contiguous\\PYZus{}us\\PYZus{}county\\PYZus{}shapefile.shp}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Path to the county boundary shapefile for the contiguous US}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{load\\PYZus{}county\\PYZus{}boundary}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{operation}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Load county boundary shapefile into GeoDataFrame}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}shp\\PYZus{}path}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{load\\PYZus{}county\\PYZus{}boundary}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{data\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{County boundary GeoDataFrame}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{load\\PYZus{}county\\PYZus{}boundary}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} 2. Collect median income data through US Census Bureau API}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{median\\PYZus{}income\\PYZus{}api\\PYZus{}url}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{data\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{US Census Bureau API URL for county level median income}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{collect\\PYZus{}income\\PYZus{}data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{operation}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Collect median income data using the Census API}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{median\\PYZus{}income\\PYZus{}api\\PYZus{}url}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{collect\\PYZus{}income\\PYZus{}data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{median\\PYZus{}income\\PYZus{}data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{data\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Median income data collected}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{collect\\PYZus{}income\\PYZus{}data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{median\\PYZus{}income\\PYZus{}data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} 3. Join median income data to the county boundaries}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{join\\PYZus{}income\\PYZus{}to\\PYZus{}boundary}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{operation}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Join median income data to county boundary GeoDataFrame on a common attribute}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{median\\PYZus{}income\\PYZus{}data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{join\\PYZus{}income\\PYZus{}to\\PYZus{}boundary}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{join\\PYZus{}income\\PYZus{}to\\PYZus{}boundary}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}income\\PYZus{}gdf}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{data\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{County boundary GeoDataFrame with median income data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{join\\PYZus{}income\\PYZus{}to\\PYZus{}boundary}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}income\\PYZus{}gdf}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} 4. Generate map to show spatial distribution of median income}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{generate\\PYZus{}income\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{operation}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Generate a map showing the spatial distribution of median income at the county level}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{county\\PYZus{}income\\PYZus{}gdf}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{generate\\PYZus{}income\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}node}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{income\\PYZus{}distribution\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{node\\PYZus{}type}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{data}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{data\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{description}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Map showing spatial distribution of county level median income}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\PY{n}{G}\\PY{o}{.}\\PY{n}{add\\PYZus{}edge}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{generate\\PYZus{}income\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{income\\PYZus{}distribution\\PYZus{}map}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Save the graph to a GraphML file}\n",
       "\\PY{n}{nx}\\PY{o}{.}\\PY{n}{write\\PYZus{}graphml}\\PY{p}{(}\\PY{n}{G}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{D:}\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{OneDrive\\PYZus{}PSU}\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{OneDrive \\PYZhy{} The Pennsylvania State University}\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{Research\\PYZus{}doc}\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{LLM\\PYZus{}Geo}\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{Python\\PYZus{}code}\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{Census\\PYZus{}API}\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{Census\\PYZus{}API.graphml}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import networkx as nx\n",
       "\n",
       "G = nx.DiGraph()\n",
       "\n",
       "# 1. Load county boundary shapefile for the contiguous US\n",
       "G.add_node(\"county_shp_path\", node_type=\"data\", data_path=\"path/to/contiguous_us_county_shapefile.shp\", description=\"Path to the county boundary shapefile for the contiguous US\")\n",
       "G.add_node(\"load_county_boundary\", node_type=\"operation\", description=\"Load county boundary shapefile into GeoDataFrame\")\n",
       "G.add_edge(\"county_shp_path\", \"load_county_boundary\")\n",
       "G.add_node(\"county_boundary_gdf\", node_type=\"data\", data_path=\"\", description=\"County boundary GeoDataFrame\")\n",
       "G.add_edge(\"load_county_boundary\", \"county_boundary_gdf\")\n",
       "\n",
       "# 2. Collect median income data through US Census Bureau API\n",
       "G.add_node(\"median_income_api_url\", node_type=\"data\", data_path=\"\", description=\"US Census Bureau API URL for county level median income\")\n",
       "G.add_node(\"collect_income_data\", node_type=\"operation\", description=\"Collect median income data using the Census API\")\n",
       "G.add_edge(\"median_income_api_url\", \"collect_income_data\")\n",
       "G.add_node(\"median_income_data\", node_type=\"data\", data_path=\"\", description=\"Median income data collected\")\n",
       "G.add_edge(\"collect_income_data\", \"median_income_data\")\n",
       "\n",
       "# 3. Join median income data to the county boundaries\n",
       "G.add_node(\"join_income_to_boundary\", node_type=\"operation\", description=\"Join median income data to county boundary GeoDataFrame on a common attribute\")\n",
       "G.add_edge(\"median_income_data\", \"join_income_to_boundary\")\n",
       "G.add_edge(\"county_boundary_gdf\", \"join_income_to_boundary\")\n",
       "G.add_node(\"county_income_gdf\", node_type=\"data\", data_path=\"\", description=\"County boundary GeoDataFrame with median income data\")\n",
       "G.add_edge(\"join_income_to_boundary\", \"county_income_gdf\")\n",
       "\n",
       "# 4. Generate map to show spatial distribution of median income\n",
       "G.add_node(\"generate_income_map\", node_type=\"operation\", description=\"Generate a map showing the spatial distribution of median income at the county level\")\n",
       "G.add_edge(\"county_income_gdf\", \"generate_income_map\")\n",
       "G.add_node(\"income_distribution_map\", node_type=\"data\", data_path=\"\", description=\"Map showing spatial distribution of county level median income\")\n",
       "G.add_edge(\"generate_income_map\", \"income_distribution_map\")\n",
       "\n",
       "# Save the graph to a GraphML file\n",
       "nx.write_graphml(G, \"D:\\\\OneDrive_PSU\\\\OneDrive - The Pennsylvania State University\\\\Research_doc\\\\LLM_Geo\\\\Python_code\\\\Census_API\\\\Census_API.graphml\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_for_graph = solution.get_LLM_response_for_graph() \n",
    "solution.graph_response = response_for_graph\n",
    "solution.save_solution()\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(Code(solution.code_for_graph, language='python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112017eb-8bcb-4d44-88d5-7099f22bf107",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute code to generate the solution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1695d40-b164-4d8b-8381-957ce260a5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\Python_code\\Census_API.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\Python_code\\Census_API.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d4feef6270>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(solution.code_for_graph)\n",
    "solution_graph = solution.load_graph_file()\n",
    "\n",
    "# Show the graph\n",
    "G = nx.read_graphml(solution.graph_file)  \n",
    "nt = helper.show_graph(G)\n",
    "html_name = os.path.join(os.getcwd(), solution.task_name + '.html')  \n",
    "# HTML file should in the same directory. See:\n",
    "# https://stackoverflow.com/questions/65564916/error-displaying-pyvis-html-inside-jupyter-lab-cell\n",
    "nt.show(name=html_name)\n",
    "# html_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8311-1874-4b23-957c-793cfd74a9cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for operations (functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4459452-8156-476d-8d20-1fccf3fdaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">geopandas</span> <span class=\"k\">as</span> <span class=\"nn\">gpd</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">load_county_boundary</span><span class=\"p\">(</span><span class=\"n\">county_shp_path</span><span class=\"o\">=</span><span class=\"s1\">&#39;path/to/contiguous_us_county_shapefile.shp&#39;</span><span class=\"p\">):</span>\n",
       "    <span class=\"c1\"># Description: Load county boundary shapefile into GeoDataFrame</span>\n",
       "    <span class=\"n\">county_boundary_gdf</span> <span class=\"o\">=</span> <span class=\"n\">gpd</span><span class=\"o\">.</span><span class=\"n\">read_file</span><span class=\"p\">(</span><span class=\"n\">county_shp_path</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">county_boundary_gdf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">requests</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">collect_income_data</span><span class=\"p\">(</span><span class=\"n\">median_income_api_url</span><span class=\"p\">):</span>\n",
       "    <span class=\"c1\"># Description: Collect median income data using the Census API</span>\n",
       "    <span class=\"c1\"># median_income_api_url: US Census Bureau API URL for county level median income</span>\n",
       "\n",
       "    <span class=\"c1\"># Fetch the data from the API</span>\n",
       "    <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"n\">median_income_api_url</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">raise_for_status</span><span class=\"p\">()</span>  <span class=\"c1\"># Raise an error for bad responses</span>\n",
       "\n",
       "    <span class=\"c1\"># Load the data into a DataFrame</span>\n",
       "    <span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">json</span><span class=\"p\">()</span>\n",
       "    \n",
       "    <span class=\"c1\"># Convert JSON data to DataFrame and set the first row as header</span>\n",
       "    <span class=\"n\">median_income_data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">:],</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"n\">data</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n",
       "    \n",
       "    <span class=\"c1\"># Ensure &#39;GEOID&#39; is string type to maintain leading zeros, drop rows with NaN in critical columns</span>\n",
       "    <span class=\"n\">median_income_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">median_income_data</span><span class=\"p\">[</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">str</span><span class=\"o\">.</span><span class=\"n\">zfill</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">median_income_data</span><span class=\"o\">.</span><span class=\"n\">dropna</span><span class=\"p\">(</span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;median_income&#39;</span><span class=\"p\">],</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Keep only necessary columns for joining</span>\n",
       "    <span class=\"n\">median_income_data</span> <span class=\"o\">=</span> <span class=\"n\">median_income_data</span><span class=\"p\">[[</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;median_income&#39;</span><span class=\"p\">]]</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">median_income_data</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">geopandas</span> <span class=\"k\">as</span> <span class=\"nn\">gpd</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">join_income_to_boundary</span><span class=\"p\">(</span><span class=\"n\">county_boundary_gdf</span><span class=\"p\">,</span> <span class=\"n\">median_income_data</span><span class=\"p\">):</span>\n",
       "    <span class=\"c1\"># Description: Join median income data to county boundary GeoDataFrame on a common attribute</span>\n",
       "\n",
       "    <span class=\"c1\"># Ensure &#39;GEOID&#39; is string type to maintain leading zeros for joining</span>\n",
       "    <span class=\"n\">county_boundary_gdf</span><span class=\"p\">[</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">county_boundary_gdf</span><span class=\"p\">[</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">str</span><span class=\"o\">.</span><span class=\"n\">zfill</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Drop any rows with NaN in the GEOID column in county_boundary_gdf</span>\n",
       "    <span class=\"n\">county_boundary_gdf</span><span class=\"o\">.</span><span class=\"n\">dropna</span><span class=\"p\">(</span><span class=\"n\">subset</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">],</span> <span class=\"n\">inplace</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Perform the join operation</span>\n",
       "    <span class=\"n\">county_income_gdf</span> <span class=\"o\">=</span> <span class=\"n\">county_boundary_gdf</span><span class=\"o\">.</span><span class=\"n\">merge</span><span class=\"p\">(</span><span class=\"n\">median_income_data</span><span class=\"p\">,</span> <span class=\"n\">on</span><span class=\"o\">=</span><span class=\"s1\">&#39;GEOID&#39;</span><span class=\"p\">,</span> <span class=\"n\">how</span><span class=\"o\">=</span><span class=\"s1\">&#39;inner&#39;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">county_income_gdf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">geopandas</span> <span class=\"k\">as</span> <span class=\"nn\">gpd</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">generate_income_map</span><span class=\"p\">(</span><span class=\"n\">county_income_gdf</span><span class=\"p\">):</span>\n",
       "    <span class=\"c1\"># Description: Generate a map showing the spatial distribution of median income at the county level</span>\n",
       "    \n",
       "    <span class=\"c1\"># Check if county_income_gdf CRS is in a projected coordinate system, otherwise convert it</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">county_income_gdf</span><span class=\"o\">.</span><span class=\"n\">crs</span><span class=\"o\">.</span><span class=\"n\">to_string</span><span class=\"p\">()</span> <span class=\"o\">!=</span> <span class=\"s2\">&quot;EPSG:4326&quot;</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">county_income_gdf</span> <span class=\"o\">=</span> <span class=\"n\">county_income_gdf</span><span class=\"o\">.</span><span class=\"n\">to_crs</span><span class=\"p\">(</span><span class=\"n\">epsg</span><span class=\"o\">=</span><span class=\"mi\">4326</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Prepare the plot</span>\n",
       "    <span class=\"n\">fig</span><span class=\"p\">,</span> <span class=\"n\">ax</span> <span class=\"o\">=</span> <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">subplots</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">figsize</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">25</span><span class=\"p\">,</span> <span class=\"mi\">15</span><span class=\"p\">))</span>\n",
       "    \n",
       "    <span class=\"c1\"># Plot the counties with median income</span>\n",
       "    <span class=\"n\">county_income_gdf</span><span class=\"o\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">column</span><span class=\"o\">=</span><span class=\"s1\">&#39;median_income&#39;</span><span class=\"p\">,</span> <span class=\"n\">ax</span><span class=\"o\">=</span><span class=\"n\">ax</span><span class=\"p\">,</span> <span class=\"n\">legend</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\n",
       "                           <span class=\"n\">legend_kwds</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;label&#39;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;Median Income by County&quot;</span><span class=\"p\">,</span>\n",
       "                                        <span class=\"s1\">&#39;orientation&#39;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;horizontal&quot;</span><span class=\"p\">},</span>\n",
       "                           <span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s1\">&#39;OrRd&#39;</span><span class=\"p\">)</span>\n",
       "    \n",
       "    <span class=\"c1\"># Set axis off for the map</span>\n",
       "    <span class=\"n\">ax</span><span class=\"o\">.</span><span class=\"n\">set_axis_off</span><span class=\"p\">()</span>\n",
       "    \n",
       "    <span class=\"c1\"># Set title</span>\n",
       "    <span class=\"n\">ax</span><span class=\"o\">.</span><span class=\"n\">set_title</span><span class=\"p\">(</span><span class=\"s1\">&#39;Spatial Distribution of Median Income at the County Level&#39;</span><span class=\"p\">,</span> \n",
       "                 <span class=\"n\">fontdict</span><span class=\"o\">=</span><span class=\"p\">{</span><span class=\"s1\">&#39;fontsize&#39;</span><span class=\"p\">:</span> <span class=\"mi\">20</span><span class=\"p\">},</span> <span class=\"n\">loc</span><span class=\"o\">=</span><span class=\"s1\">&#39;center&#39;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Save the map</span>\n",
       "    <span class=\"n\">income_distribution_map</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;income_distribution_map.png&quot;</span>\n",
       "    <span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">savefig</span><span class=\"p\">(</span><span class=\"n\">income_distribution_map</span><span class=\"p\">,</span> <span class=\"n\">bbox_inches</span><span class=\"o\">=</span><span class=\"s1\">&#39;tight&#39;</span><span class=\"p\">,</span> <span class=\"n\">pad_inches</span><span class=\"o\">=</span><span class=\"mf\">0.1</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Return the path to the saved map</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">income_distribution_map</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{geopandas} \\PY{k}{as} \\PY{n+nn}{gpd}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{load\\PYZus{}county\\PYZus{}boundary}\\PY{p}{(}\\PY{n}{county\\PYZus{}shp\\PYZus{}path}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{path/to/contiguous\\PYZus{}us\\PYZus{}county\\PYZus{}shapefile.shp}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Description: Load county boundary shapefile into GeoDataFrame}\n",
       "    \\PY{n}{county\\PYZus{}boundary\\PYZus{}gdf} \\PY{o}{=} \\PY{n}{gpd}\\PY{o}{.}\\PY{n}{read\\PYZus{}file}\\PY{p}{(}\\PY{n}{county\\PYZus{}shp\\PYZus{}path}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{county\\PYZus{}boundary\\PYZus{}gdf}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{requests}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{collect\\PYZus{}income\\PYZus{}data}\\PY{p}{(}\\PY{n}{median\\PYZus{}income\\PYZus{}api\\PYZus{}url}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Description: Collect median income data using the Census API}\n",
       "    \\PY{c+c1}{\\PYZsh{} median\\PYZus{}income\\PYZus{}api\\PYZus{}url: US Census Bureau API URL for county level median income}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Fetch the data from the API}\n",
       "    \\PY{n}{response} \\PY{o}{=} \\PY{n}{requests}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{n}{median\\PYZus{}income\\PYZus{}api\\PYZus{}url}\\PY{p}{)}\n",
       "    \\PY{n}{response}\\PY{o}{.}\\PY{n}{raise\\PYZus{}for\\PYZus{}status}\\PY{p}{(}\\PY{p}{)}  \\PY{c+c1}{\\PYZsh{} Raise an error for bad responses}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Load the data into a DataFrame}\n",
       "    \\PY{n}{data} \\PY{o}{=} \\PY{n}{response}\\PY{o}{.}\\PY{n}{json}\\PY{p}{(}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} Convert JSON data to DataFrame and set the first row as header}\n",
       "    \\PY{n}{median\\PYZus{}income\\PYZus{}data} \\PY{o}{=} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{(}\\PY{n}{data}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{:}\\PY{p}{]}\\PY{p}{,} \\PY{n}{columns}\\PY{o}{=}\\PY{n}{data}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} Ensure \\PYZsq{}GEOID\\PYZsq{} is string type to maintain leading zeros, drop rows with NaN in critical columns}\n",
       "    \\PY{n}{median\\PYZus{}income\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n}{median\\PYZus{}income\\PYZus{}data}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{astype}\\PY{p}{(}\\PY{n+nb}{str}\\PY{p}{)}\\PY{o}{.}\\PY{n}{str}\\PY{o}{.}\\PY{n}{zfill}\\PY{p}{(}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "    \\PY{n}{median\\PYZus{}income\\PYZus{}data}\\PY{o}{.}\\PY{n}{dropna}\\PY{p}{(}\\PY{n}{subset}\\PY{o}{=}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{median\\PYZus{}income}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Keep only necessary columns for joining}\n",
       "    \\PY{n}{median\\PYZus{}income\\PYZus{}data} \\PY{o}{=} \\PY{n}{median\\PYZus{}income\\PYZus{}data}\\PY{p}{[}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{median\\PYZus{}income}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{]}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{median\\PYZus{}income\\PYZus{}data}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{geopandas} \\PY{k}{as} \\PY{n+nn}{gpd}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{pandas} \\PY{k}{as} \\PY{n+nn}{pd}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{join\\PYZus{}income\\PYZus{}to\\PYZus{}boundary}\\PY{p}{(}\\PY{n}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{p}{,} \\PY{n}{median\\PYZus{}income\\PYZus{}data}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Description: Join median income data to county boundary GeoDataFrame on a common attribute}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Ensure \\PYZsq{}GEOID\\PYZsq{} is string type to maintain leading zeros for joining}\n",
       "    \\PY{n}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]} \\PY{o}{=} \\PY{n}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{o}{.}\\PY{n}{astype}\\PY{p}{(}\\PY{n+nb}{str}\\PY{p}{)}\\PY{o}{.}\\PY{n}{str}\\PY{o}{.}\\PY{n}{zfill}\\PY{p}{(}\\PY{l+m+mi}{5}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Drop any rows with NaN in the GEOID column in county\\PYZus{}boundary\\PYZus{}gdf}\n",
       "    \\PY{n}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{o}{.}\\PY{n}{dropna}\\PY{p}{(}\\PY{n}{subset}\\PY{o}{=}\\PY{p}{[}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{inplace}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Perform the join operation}\n",
       "    \\PY{n}{county\\PYZus{}income\\PYZus{}gdf} \\PY{o}{=} \\PY{n}{county\\PYZus{}boundary\\PYZus{}gdf}\\PY{o}{.}\\PY{n}{merge}\\PY{p}{(}\\PY{n}{median\\PYZus{}income\\PYZus{}data}\\PY{p}{,} \\PY{n}{on}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GEOID}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{how}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{inner}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{county\\PYZus{}income\\PYZus{}gdf}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{matplotlib}\\PY{n+nn}{.}\\PY{n+nn}{pyplot} \\PY{k}{as} \\PY{n+nn}{plt}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{geopandas} \\PY{k}{as} \\PY{n+nn}{gpd}\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{generate\\PYZus{}income\\PYZus{}map}\\PY{p}{(}\\PY{n}{county\\PYZus{}income\\PYZus{}gdf}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{c+c1}{\\PYZsh{} Description: Generate a map showing the spatial distribution of median income at the county level}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} Check if county\\PYZus{}income\\PYZus{}gdf CRS is in a projected coordinate system, otherwise convert it}\n",
       "    \\PY{k}{if} \\PY{n}{county\\PYZus{}income\\PYZus{}gdf}\\PY{o}{.}\\PY{n}{crs}\\PY{o}{.}\\PY{n}{to\\PYZus{}string}\\PY{p}{(}\\PY{p}{)} \\PY{o}{!=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{EPSG:4326}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "        \\PY{n}{county\\PYZus{}income\\PYZus{}gdf} \\PY{o}{=} \\PY{n}{county\\PYZus{}income\\PYZus{}gdf}\\PY{o}{.}\\PY{n}{to\\PYZus{}crs}\\PY{p}{(}\\PY{n}{epsg}\\PY{o}{=}\\PY{l+m+mi}{4326}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Prepare the plot}\n",
       "    \\PY{n}{fig}\\PY{p}{,} \\PY{n}{ax} \\PY{o}{=} \\PY{n}{plt}\\PY{o}{.}\\PY{n}{subplots}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,} \\PY{l+m+mi}{1}\\PY{p}{,} \\PY{n}{figsize}\\PY{o}{=}\\PY{p}{(}\\PY{l+m+mi}{25}\\PY{p}{,} \\PY{l+m+mi}{15}\\PY{p}{)}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} Plot the counties with median income}\n",
       "    \\PY{n}{county\\PYZus{}income\\PYZus{}gdf}\\PY{o}{.}\\PY{n}{plot}\\PY{p}{(}\\PY{n}{column}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{median\\PYZus{}income}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{ax}\\PY{o}{=}\\PY{n}{ax}\\PY{p}{,} \\PY{n}{legend}\\PY{o}{=}\\PY{k+kc}{True}\\PY{p}{,}\n",
       "                           \\PY{n}{legend\\PYZus{}kwds}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{label}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Median Income by County}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "                                        \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{orientation}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{horizontal}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{,}\n",
       "                           \\PY{n}{cmap}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{OrRd}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} Set axis off for the map}\n",
       "    \\PY{n}{ax}\\PY{o}{.}\\PY{n}{set\\PYZus{}axis\\PYZus{}off}\\PY{p}{(}\\PY{p}{)}\n",
       "    \n",
       "    \\PY{c+c1}{\\PYZsh{} Set title}\n",
       "    \\PY{n}{ax}\\PY{o}{.}\\PY{n}{set\\PYZus{}title}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{Spatial Distribution of Median Income at the County Level}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \n",
       "                 \\PY{n}{fontdict}\\PY{o}{=}\\PY{p}{\\PYZob{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{fontsize}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{l+m+mi}{20}\\PY{p}{\\PYZcb{}}\\PY{p}{,} \\PY{n}{loc}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{center}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Save the map}\n",
       "    \\PY{n}{income\\PYZus{}distribution\\PYZus{}map} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{income\\PYZus{}distribution\\PYZus{}map.png}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "    \\PY{n}{plt}\\PY{o}{.}\\PY{n}{savefig}\\PY{p}{(}\\PY{n}{income\\PYZus{}distribution\\PYZus{}map}\\PY{p}{,} \\PY{n}{bbox\\PYZus{}inches}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{tight}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{n}{pad\\PYZus{}inches}\\PY{o}{=}\\PY{l+m+mf}{0.1}\\PY{p}{)}\n",
       "\n",
       "    \\PY{c+c1}{\\PYZsh{} Return the path to the saved map}\n",
       "    \\PY{k}{return} \\PY{n}{income\\PYZus{}distribution\\PYZus{}map}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import geopandas as gpd\n",
       "\n",
       "def load_county_boundary(county_shp_path='path/to/contiguous_us_county_shapefile.shp'):\n",
       "    # Description: Load county boundary shapefile into GeoDataFrame\n",
       "    county_boundary_gdf = gpd.read_file(county_shp_path)\n",
       "    return county_boundary_gdf\n",
       "import requests\n",
       "import pandas as pd\n",
       "\n",
       "def collect_income_data(median_income_api_url):\n",
       "    # Description: Collect median income data using the Census API\n",
       "    # median_income_api_url: US Census Bureau API URL for county level median income\n",
       "\n",
       "    # Fetch the data from the API\n",
       "    response = requests.get(median_income_api_url)\n",
       "    response.raise_for_status()  # Raise an error for bad responses\n",
       "\n",
       "    # Load the data into a DataFrame\n",
       "    data = response.json()\n",
       "    \n",
       "    # Convert JSON data to DataFrame and set the first row as header\n",
       "    median_income_data = pd.DataFrame(data[1:], columns=data[0])\n",
       "    \n",
       "    # Ensure 'GEOID' is string type to maintain leading zeros, drop rows with NaN in critical columns\n",
       "    median_income_data['GEOID'] = median_income_data['GEOID'].astype(str).str.zfill(5)\n",
       "    median_income_data.dropna(subset=['GEOID', 'median_income'], inplace=True)\n",
       "\n",
       "    # Keep only necessary columns for joining\n",
       "    median_income_data = median_income_data[['GEOID', 'median_income']]\n",
       "\n",
       "    return median_income_data\n",
       "import geopandas as gpd\n",
       "import pandas as pd\n",
       "\n",
       "def join_income_to_boundary(county_boundary_gdf, median_income_data):\n",
       "    # Description: Join median income data to county boundary GeoDataFrame on a common attribute\n",
       "\n",
       "    # Ensure 'GEOID' is string type to maintain leading zeros for joining\n",
       "    county_boundary_gdf['GEOID'] = county_boundary_gdf['GEOID'].astype(str).str.zfill(5)\n",
       "\n",
       "    # Drop any rows with NaN in the GEOID column in county_boundary_gdf\n",
       "    county_boundary_gdf.dropna(subset=['GEOID'], inplace=True)\n",
       "\n",
       "    # Perform the join operation\n",
       "    county_income_gdf = county_boundary_gdf.merge(median_income_data, on='GEOID', how='inner')\n",
       "\n",
       "    return county_income_gdf\n",
       "import matplotlib.pyplot as plt\n",
       "import geopandas as gpd\n",
       "\n",
       "def generate_income_map(county_income_gdf):\n",
       "    # Description: Generate a map showing the spatial distribution of median income at the county level\n",
       "    \n",
       "    # Check if county_income_gdf CRS is in a projected coordinate system, otherwise convert it\n",
       "    if county_income_gdf.crs.to_string() != \"EPSG:4326\":\n",
       "        county_income_gdf = county_income_gdf.to_crs(epsg=4326)\n",
       "\n",
       "    # Prepare the plot\n",
       "    fig, ax = plt.subplots(1, 1, figsize=(25, 15))\n",
       "    \n",
       "    # Plot the counties with median income\n",
       "    county_income_gdf.plot(column='median_income', ax=ax, legend=True,\n",
       "                           legend_kwds={'label': \"Median Income by County\",\n",
       "                                        'orientation': \"horizontal\"},\n",
       "                           cmap='OrRd')\n",
       "    \n",
       "    # Set axis off for the map\n",
       "    ax.set_axis_off()\n",
       "    \n",
       "    # Set title\n",
       "    ax.set_title('Spatial Distribution of Median Income at the County Level', \n",
       "                 fontdict={'fontsize': 20}, loc='center')\n",
       "\n",
       "    # Save the map\n",
       "    income_distribution_map = \"income_distribution_map.png\"\n",
       "    plt.savefig(income_distribution_map, bbox_inches='tight', pad_inches=0.1)\n",
       "\n",
       "    # Return the path to the saved map\n",
       "    return income_distribution_map"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "operations = solution.get_LLM_responses_for_operations(review=isReview)\n",
    "solution.save_solution()\n",
    "\n",
    "all_operation_code_str = '\\n'.join([operation['operation_code'] for operation in operations])\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(Code(all_operation_code_str, language='python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f735-29f4-4934-8a7e-00616447cd40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate prompts and code for assembly program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ac055d-11b8-4b3e-890c-83501611355f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import geopandas as gpd\n",
      "import pandas as pd\n",
      "import requests\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def load_county_boundary(county_shp_path='path/to/contiguous_us_county_shapefile.shp'):\n",
      "    county_boundary_gdf = gpd.read_file(county_shp_path)\n",
      "    return county_boundary_gdf\n",
      "\n",
      "def collect_income_data(median_income_api_url):\n",
      "    response = requests.get(median_income_api_url)\n",
      "    response.raise_for_status()\n",
      "\n",
      "    data = response.json()\n",
      "    median_income_data = pd.DataFrame(data[1:], columns=data[0])\n",
      "    median_income_data['GEOID'] = median_income_data['GEOID'].astype(str).str.zfill(5)\n",
      "    median_income_data.dropna(subset=['GEOID', 'median_income'], inplace=True)\n",
      "    median_income_data = median_income_data[['GEOID', 'median_income']]\n",
      "\n",
      "    return median_income_data\n",
      "\n",
      "def join_income_to_boundary(county_boundary_gdf, median_income_data):\n",
      "    county_boundary_gdf['GEOID'] = county_boundary_gdf['GEOID'].astype(str).str.zfill(5)\n",
      "    county_boundary_gdf.dropna(subset=['GEOID'], inplace=True)\n",
      "    county_income_gdf = county_boundary_gdf.merge(median_income_data, on='GEOID', how='inner')\n",
      "\n",
      "    return county_income_gdf\n",
      "\n",
      "def generate_income_map(county_income_gdf):\n",
      "    if county_income_gdf.crs.to_string() !="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m assembly_LLM_response \u001b[38;5;241m=\u001b[39m \u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_LLM_assembly_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43misReview\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m solution\u001b[38;5;241m.\u001b[39massembly_LLM_response \u001b[38;5;241m=\u001b[39m assembly_LLM_response\n\u001b[0;32m      3\u001b[0m solution\u001b[38;5;241m.\u001b[39msave_solution()\n",
      "File \u001b[1;32mD:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\Python_code\\LLM_Geo_kernel.py:366\u001b[0m, in \u001b[0;36mSolution.get_LLM_assembly_response\u001b[1;34m(self, review)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_LLM_assembly_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, review\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_for_assembly_program()\n\u001b[1;32m--> 366\u001b[0m     assembly_LLM_response \u001b[38;5;241m=\u001b[39m \u001b[43mhelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_LLM_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massembly_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m                      \u001b[49m\u001b[43msystem_role\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massembly_role\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# model=r\"gpt-4\",\u001b[39;49;00m\n\u001b[0;32m    370\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massembly_LLM_response \u001b[38;5;241m=\u001b[39m assembly_LLM_response\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode_for_assembly \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39mextract_code(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massembly_LLM_response)\n",
      "File \u001b[1;32mD:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\Python_code\\helper.py:118\u001b[0m, in \u001b[0;36mget_LLM_reply\u001b[1;34m(prompt, system_role, model, verbose, temperature, stream, retry_cnt, sleep_sec)\u001b[0m\n\u001b[0;32m    116\u001b[0m response_chucks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m--> 118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_chucks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\openai\\_streaming.py:46\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[1;32m---> 46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\openai\\_streaming.py:58\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m process_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data\n\u001b[0;32m     56\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_events()\n\u001b[1;32m---> 58\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[DONE]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\openai\\_streaming.py:50\u001b[0m, in \u001b[0;36mStream._iter_events\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39miter_bytes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_bytes())\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\openai\\_streaming.py:280\u001b[0m, in \u001b[0;36mSSEDecoder.iter_bytes\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[0;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Split before decoding so splitlines() only uses \\r and \\n\u001b[39;49;00m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mraw_line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\openai\\_streaming.py:291\u001b[0m, in \u001b[0;36mSSEDecoder._iter_chunks\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001b[39;00m\n\u001b[0;32m    290\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 291\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeepends\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpx\\_models.py:831\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    829\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 831\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpx\\_models.py:885\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    882\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 885\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpx\\_client.py:127\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m--> 127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpx\\_transports\\default.py:116\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 116\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:367\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:363\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpcore\\_sync\\http11.py:349\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpcore\\_sync\\http11.py:341\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 341\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpcore\\_sync\\http11.py:210\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    207\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32md:\\ProgramData\\anaconda3\\envs\\tgi_gpt\\Lib\\ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assembly_LLM_response = solution.get_LLM_assembly_response(review=isReview)\n",
    "solution.assembly_LLM_response = assembly_LLM_response\n",
    "solution.save_solution()\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(Code(solution.code_for_assembly, language='python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca67352-6508-4fe6-be4b-1f4649224148",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute assembly code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d7c6a-8d5a-4bca-b22e-fcb3f3d5c201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_code = all_operation_code_str + '\\n' + solution.code_for_assembly\n",
    "\n",
    "# display(Code(all_code, language='python'))\n",
    "\n",
    "all_code = solution.execute_complete_program(code=all_code, try_cnt=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb4d68-fd2e-4c46-ad04-4de208431fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4326aaf-6438-41ad-9ca0-ac393663d4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b06372-be33-4338-92ce-1450559993cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgi_gpt",
   "language": "python",
   "name": "tgi_gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
