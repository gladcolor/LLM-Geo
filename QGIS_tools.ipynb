{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405086b-b272-436c-9345-9013e9ab640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyvisa\n",
    "# ! pip install toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "464945e2-5830-4a1e-bd2e-bc3dc96c5ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os    \n",
    "import sys    \n",
    "import time\n",
    "import pprint\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e5f74-beb5-4adf-ad91-58fb3bfe41f1",
   "metadata": {},
   "source": [
    "# QGIS help page crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cda53f-1c2b-4110-b2ed-f6a8dc388876",
   "metadata": {},
   "source": [
    "## How to use?\n",
    "1. Update the `url` variable using the links in [https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/index.html](https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/index.html), e.g., [https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html](https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html).\n",
    "2. Run the program. \n",
    "\n",
    "**Please check the results manually to ensure they are correct!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8d95257d-1ecf-4552-ada7-032f8c0b91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c3bba44-f053-4f0a-aed4-da775996bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import os\n",
    "import re \n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729fc5cf-fee8-4976-932c-9bdc1955ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  28.1.23. Vector overlay â€” QGIS Documentation  documentation\n"
     ]
    }
   ],
   "source": [
    "##### These urls were processed.\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html\"\n",
    "# there are 156 sections, and 33 sections have h2 tag, while 31 tool sections.\n",
    "\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/interpolation.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectoranalysis.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorgeneral.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorgeometry.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/rasteranalysis.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/plots.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasterterrainanalysis.html\"\n",
    "\n",
    "\n",
    "url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectoroverlay.html\"\n",
    "\n",
    "def get_response(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.content\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, 'html5lib')\n",
    "        # soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Now you can work with 'soup' to extract the relevant sections\n",
    "        # Example: printing the title of the page\n",
    "        print(\"Title: \", soup.title.get_text())\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        \n",
    "    return soup\n",
    "\n",
    "soup = get_response(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f06f44-3638-45a0-9998-9c76bd0d3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84a6df-f70f-4c72-8315-89411fe6eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sections = soup.find_all('section')\n",
    "len(raw_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e8e84-a57b-4fc4-9803-51eb3fed2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, section in enumerate(sections):\n",
    "    # print(idx)\n",
    "    # print(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc07ac1-e636-4f1e-bdaf-452f54bb6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections(soup):\n",
    "    raw_sections = soup.find_all('section')\n",
    "    len(raw_sections)\n",
    "    cnt = 0\n",
    "    sections = []\n",
    "    for idx, section in enumerate(raw_sections):\n",
    "\n",
    "        section_id = section.get('id')  # Extract the section ID\n",
    "        tag = section.find('h2')  # Try to find an <h3> tag in the section\n",
    "        # print(tag)\n",
    "        if tag:\n",
    "            cnt += 1\n",
    "            print(idx, cnt, f\"Section with ID '{section_id}' contains an <h3> tag: '{tag.get_text()}'\")\n",
    "            # cnt += 1\n",
    "            sections.append(section)\n",
    "        else:\n",
    "            # print(idx, f\"Section with ID '{section_id}' does not contain an <h3> tag.\")\n",
    "            pass\n",
    "    # len(sections)  \n",
    "    return sections\n",
    "\n",
    "sections = get_sections(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abdfe5-b191-4f7d-aa31-8c3f483e2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_by_heading(section, level, heading):        \n",
    "    tags = section.find_all(level)\n",
    "    for tag in tags:\n",
    "        if heading in tag.get_text():\n",
    "            section_tag = tag.find_parent('section')\n",
    "            # print(section_tag.prettify())  # Print the entire section for visualization\n",
    "            return section_tag\n",
    "    return None\n",
    "    \n",
    "def extract_table(section):\n",
    "    # print(\"section:\", section)\n",
    "    table_data = []\n",
    "    tables = section.find_all('table')\n",
    "    # print(\"table:\", table)\n",
    "    for table in tables:\n",
    "        if table:\n",
    "            headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "            rows = table.find_all('tr')[1:]  # Skip header row\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                # row_data = {headers[i]: cols[i].get_text(strip=True) for i in range(len(headers))}\n",
    "                row_data = {headers[i]: cols[i].get_text(separator=' ', strip=True) for i in range(len(headers))}\n",
    "                table_data.append(row_data)\n",
    "    return table_data\n",
    "    \n",
    "# Helper function to normalize whitespace in a string\n",
    "def normalize_whitespace(text):\n",
    "    # Replace multiple spaces and newlines with a single space\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "# Function to extract paragraphs before a section with a specific id and ensure spaces around <a> and <code> elements\n",
    "def extract_paragraphs_before(section, stop_section_id):\n",
    "    paragraphs = []\n",
    "    \n",
    "    for element in section.find_all(['p', 'h3'], recursive=False):\n",
    "        # Stop if we encounter the sub-section (like \"Parameters\")\n",
    "        if element.name == 'h3' and stop_section_id in element.get('id', ''):\n",
    "            break\n",
    "        if element.name == 'p':\n",
    "            # Rebuild the paragraph's text, ensuring spaces around <a> and <code> tags\n",
    "            paragraph_text = []\n",
    "            for content in element.children:\n",
    "                \n",
    "                if content.name in ['a', 'code']:\n",
    "                    paragraph_text.append(f\" {content.get_text(strip=True)} \")\n",
    "                    # print(content)\n",
    "                else:\n",
    "                    paragraph_text.append(content if isinstance(content, str) else content.get_text(strip=True))\n",
    "                    # print(paragraph_text[-1])\n",
    "            \n",
    "            paragraphs.append(normalize_whitespace(''.join(paragraph_text)))\n",
    "    \n",
    "    return paragraphs\n",
    "    \n",
    "def make_parameters_for_TOML(tool_info):\n",
    "    lines = []\n",
    "    # for parameter in tool_info['basic_parameters']:\n",
    "    #     line = f\"{parameter['Name']}: {parameter['Description'].replace('\\n', '')}. Type: {parameter['Type']}\"\n",
    "    #     lines.append(line)\n",
    "        \n",
    "    # for parameter in tool_info['advanced_parameters']:\n",
    "    #     line = f\"{parameter['Name']}: {parameter['Description'].replace('\\n', '')}. Type: {parameter['Type']}\"\n",
    "    #     lines.append(line)\n",
    "\n",
    "    for parameter in tool_info['parameters']:\n",
    "        name = parameter['Name']\n",
    "        label = parameter['Label'].replace('\\n', '')\n",
    "        description = parameter['Description'].replace('\\n', '')\n",
    "        param_type = parameter['Type']\n",
    "\n",
    "        line = f\"{name}: {label}. {description}. Type: {param_type}\"\n",
    "        lines.append(line)\n",
    "    \n",
    "    para_str = \"\\n\".join(lines)\n",
    "    return para_str\n",
    "\n",
    "def make_outputs_for_TOML(tool_info):\n",
    "    lines = []\n",
    "    for output in tool_info['outputs']:\n",
    "        try:\n",
    "            name = output['Name']\n",
    "            label = output['Label'].replace('\\n', '')\n",
    "            description = output['Description'].replace('\\n', '')\n",
    "            output_type = output['Type']\n",
    "\n",
    "            line = f\"{name}: {label}. {description}. Type: {output_type}\"\n",
    "            lines.append(line)\n",
    "        except Exception as e:\n",
    "            print(\"Error in make_outputs_for_TOML():\", e)\n",
    "    \n",
    "    para_str = \"\\n\".join(lines)\n",
    "    return para_str\n",
    "def make_TOML_file(tool_info, fname):\n",
    "    tool_toml = {}\n",
    "    tool_toml['tool_ID'] = tool_info['algorithm_id']\n",
    "    tool_toml['tool_name'] = tool_info['tool_name']    \n",
    "    tool_toml['brief_description'] = tool_info['brief_description']\n",
    "    tool_toml['full_description'] = '\\n'.join(tool_info['paragraphs'])\n",
    "    tool_toml['parameters'] = make_parameters_for_TOML(tool_info)\n",
    "    tool_toml['outputs'] = make_outputs_for_TOML(tool_info)\n",
    "    tool_toml['code_example'] = \"\"\n",
    "    with open(fname, 'w', encoding='utf-8') as f:  # charmap' codec can't encode character\n",
    "        toml_str = toml.dump(tool_toml, f)\n",
    "        \n",
    "    # toml_str = toml.dumps(tool_toml)\n",
    "    return toml_str\n",
    "    \n",
    "def extract_tool_info(section):\n",
    "\n",
    "    tool_info = {}\n",
    "    section_id = section.get('id')\n",
    "    # print(\"section_id:\", section_id)\n",
    "    \n",
    "    h2 = section.find(\"h2\")\n",
    "    \n",
    "    if h2:  # Check if an h2 element was found\n",
    "\n",
    "        paragraph = section.find(\"p\")\n",
    "        if paragraph:\n",
    "            paragraphs = extract_paragraphs_before(section, 'parameters')\n",
    " \n",
    "            if len(paragraphs) > 0:\n",
    "                tool_info['brief_description'] = paragraphs[0]\n",
    "                # print(\"Tool description:\", tool_info['brief_description'])  \n",
    "            else: \n",
    "                tool_info['brief_description'] = \"\"\n",
    "            tool_info['tool_name'] = h2.get_text(strip=True)[:-1].split(\".\")[-1] \n",
    "            tool_info['paragraphs'] = paragraphs\n",
    "  \n",
    "        algorithm_id = None \n",
    "        python_code_snippet = None\n",
    "        \n",
    "        python_code_section = get_section_by_heading(section, 'h3', 'Python code')\n",
    "        if python_code_section: \n",
    "            algorithm_id = python_code_section.find('code').get_text(strip=True)\n",
    "            if not algorithm_id:\n",
    "                return tool_info\n",
    "            # print(\"algorithm_id:\", algorithm_id) \n",
    "            pre_tag = python_code_section.find('pre')\n",
    "            # print(\"python_code_section:\", python_code_section)\n",
    "            if pre_tag:\n",
    "                python_code_snippet = pre_tag.get_text()\n",
    "            # print(\"algorithm_id:\", algorithm_id) \n",
    "\n",
    "        # store algorithm_id\n",
    "        tool_info['algorithm_id'] = algorithm_id\n",
    "        tool_info['python_code_snippet'] = python_code_snippet\n",
    "\n",
    "        paremeters_section = get_section_by_heading(section, 'h3', 'Parameters')\n",
    "        if paremeters_section:\n",
    "            # print(\"paremeters_section:\", paremeters_section)\n",
    "            # basic_parameters_section = section.find('section', id='basic-parameters')   # only for 28.1.15. Raster analysis \n",
    "            # advanced_parameters_section = section.find('section', id='advanced-parameters') # only for 28.1.15. Raster analysis\n",
    "            \n",
    "            \n",
    "            # basic_parameters = extract_table(basic_parameters_section) if basic_parameters_section else []  # only for 28.1.15. Raster analysis\n",
    "            # advanced_parameters = extract_table(advanced_parameters_section) if advanced_parameters_section else []  # only for 28.1.15. Raster analysis\n",
    "            parameters = extract_table(paremeters_section) if paremeters_section else [] \n",
    "            # print(\"parameters:\", parameters)\n",
    "\n",
    "            # tool_info['basic_parameters'] = basic_parameters   # only for 28.1.15. Raster analysis\n",
    "            # tool_info['advanced_parameters'] = advanced_parameters   # only for 28.1.15. Raster analysis\n",
    "            tool_info['parameters'] = parameters\n",
    "            \n",
    "\n",
    "        outputs_section = get_section_by_heading(section, 'h3', 'Outputs')\n",
    "        if outputs_section:\n",
    "            outputs = extract_table(outputs_section) if outputs_section else []\n",
    "            tool_info['outputs'] = outputs\n",
    "            # print(\"outputs:\", outputs)\n",
    "\n",
    "        # print(tool_info)\n",
    "        # print(\"Tool description:\", tool_info['brief_description'])  \n",
    "        return tool_info\n",
    "    else:\n",
    "        # print(\"No h2 found in this section.\")\n",
    "        pass\n",
    "        \n",
    "    return tool_info\n",
    "\n",
    "\n",
    "save_dir = r'D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\QGIS_plugin\\toml'\n",
    "\n",
    "count = 0\n",
    "\n",
    "for section in sections[2:]:\n",
    "    try:\n",
    "        tool_info = extract_tool_info(section)    \n",
    "        tool_name = tool_info['algorithm_id'].replace(\":\", \"_\")\n",
    "        \n",
    "        fname = os.path.join(save_dir, f\"{tool_name}.toml\")\n",
    "        toml_str = make_TOML_file(tool_info, fname)\n",
    "        # print(\"fname:\", fname)\n",
    "        count += 1\n",
    "\n",
    "        print(f\"{count} tool_name:\", tool_name)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"error:\", e)\n",
    "        pass\n",
    "\n",
    "    # if count > 0: \n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e4d1e-2755-41c8-a58d-06fa84bc453c",
   "metadata": {},
   "source": [
    "# Download a url list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672d66e-926e-4a8d-a04a-cb94e45fb1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/3dtiles.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/cartography.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/database.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/filetools.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/gps.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/interpolation.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/layertools.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/mesh.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/modelertools.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/networkanalysis.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/plots.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/pointcloudconversion.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/pointclouddatamanagement.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/pointcloudextraction.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rastercreation.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasterterrainanalysis.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rastertools.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectoranalysis.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorcreation.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorgeneral.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorgeometry.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectoroverlay.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorselection.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectortable.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectortiles.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/index.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/rasteranalysis.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/rasterconversion.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/rasterextraction.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/rastermiscellaneous.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/rasterprojections.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/vectorconversion.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/vectorgeoprocessing.html\",\n",
    "\"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/vectormiscellaneous.html\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c49d6-2509-4303-a091-958992f6a62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d40da-06a6-416a-89b7-db99ce2b8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = r'D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\QGIS_plugin\\toml'\n",
    "\n",
    "\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    print(f\"Processing: {idx + 1} / {len(urls)}\",  url)\n",
    "    \n",
    "    soup = get_response(url)\n",
    "    sections = get_sections(soup)\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for section in sections[2:]:\n",
    "        try:\n",
    "            tool_info = extract_tool_info(section)    \n",
    "            tool_name = tool_info['algorithm_id'].replace(\":\", \"_\")\n",
    "\n",
    "            fname = os.path.join(save_dir, f\"{tool_name}.toml\")\n",
    "            toml_str = make_TOML_file(tool_info, fname)\n",
    "            # print(\"fname:\", fname)\n",
    "            count += 1\n",
    "\n",
    "            print(f\"{count} tool_name:\", tool_name)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"error:\", e)\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf873d39-0ef0-456f-856d-12c7128cb95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = ['Tessellate', 'Aspect', 'Assign projection', 'Buffer vectors', 'Build virtual raster', 'Build virtual vector', 'Clip raster by extent', 'Clip raster by mask layer', 'Clip vector by extent', 'Clip vector by mask layer', 'Color relief', 'Contour', 'Contour Polygons', 'Convert format', 'Dissolve', 'Execute SQL', 'Extract projection', 'Fill nodata', 'gdal2tiles', 'gdal2xyz', 'Raster information', 'Grid (Moving average)', 'Grid (Data metrics)', 'Grid (Inverse distance to a power)', 'Grid (IDW with nearest neighbor searching)', 'Grid (Linear)', 'Grid (Nearest neighbor)', 'Hillshade', 'Export to PostgreSQL (available connections)', 'Export to PostgreSQL (new connection)', 'Merge', 'Near black', 'Offset curve', 'Vector information', 'One side buffer', 'Build overviews (pyramids)', 'Pansharpening', 'PCT to RGB', 'Points along lines', 'Polygonize (raster to vector)', 'Proximity (raster distance)', 'Raster calculator', 'Rasterize (vector to raster)', 'Rasterize (overwrite with attribute)', 'Rasterize (overwrite with fixed value)', 'Rearrange bands', 'Retile', 'RGB to PCT', 'Roughness', 'Sieve', 'Slope', 'Tile index', 'Topographic Position Index (TPI)', 'Translate (convert format)', 'Terrain Ruggedness Index (TRI)', 'Viewshed', 'Warp (reproject)', 'g.extension.list', 'g.extension.manage', 'i.albedo', 'i.aster.toar', 'i.atcorr', 'i.biomass', 'i.cca', 'i.cluster', 'i.colors.enhance', 'i.eb.eta', 'i.eb.evapfr', 'i.eb.hsebal01.coords', 'i.eb.netrad', 'i.eb.soilheatflux', 'i.emissivity', 'i.evapo.mh', 'i.evapo.pm', 'i.evapo.pt', 'i.evapo.time', 'i.fft', 'i.gensig', 'i.gensigset', 'i.group', 'i.his.rgb', 'i.ifft', 'i.image.mosaic', 'i.in.spotvgt', 'i.landsat.acca', 'i.landsat.toar', 'i.maxlik', 'i.modis.qc', 'i.oif', 'i.pansharpen', 'i.pca', 'i.rgb.his', 'i.segment', 'i.smap', 'i.tasscap', 'i.topo.coor.ill', 'i.topo.corr', 'i.vi', 'i.zc', 'm.cogo', 'nviz', 'r.basins.fill', 'r.blend.combine', 'r.blend.rgb', 'r.buffer', 'r.buffer.lowmem', 'r.carve', 'r.category', 'r.category.out', 'r.circle', 'r.clump', 'r.coin', 'r.colors', 'r.colors.out', 'r.colors.stddev', 'r.composite', 'r.contour', 'r.cost', 'r.covar', 'r.cross', 'r.describe', 'r.distance', 'r.drain', 'r.fill.dir', 'r.fill.stats', 'r.fillnulls', 'r.flow', 'r.geomorphon', 'r.grow', 'r.grow.distance', 'r.gwflow', 'r.his', 'r.horizon', 'r.horizon.height', 'r.in.lidar', 'r.in.lidar.info', 'r.info', 'r.kappa', 'r.lake', 'r.latlong', 'r.li.cwed', 'r.li.cwed.ascii', 'r.li.dominance', 'r.li.dominance.ascii', 'r.li.edgedensity', 'r.li.edgedensity.ascii', 'r.li.mpa', 'r.li.mpa.ascii', 'r.li.mps', 'r.li.mps.ascii', 'r.li.padcv', 'r.li.padcv.ascii', 'r.li.padrange', 'r.li.padrange.ascii', 'r.li.padsd', 'r.li.padsd.ascii', 'r.li.patchdensity', 'r.li.patchdensity.ascii', 'r.li.patchnum', 'r.li.patchnum.ascii', 'r.li.pielou', 'r.li.pielou.ascii', 'r.li.renyi', 'r.li.renyi.ascii', 'r.li.richness', 'r.li.richness.ascii', 'r.li.shannon', 'r.li.shannon.ascii', 'r.li.shape', 'r.li.shape.ascii', 'r.li.simpson', 'r.li.simpson.ascii', 'r.mapcalc.simple', 'r.mask.rast', 'r.mask.vect', 'r.mfilter', 'r.mode', 'r.neighbors', 'r.null', 'r.out.ascii', 'r.out.gridatb', 'r.out.mat', 'r.out.mpeg', 'r.out.png', 'r.out.pov', 'r.out.ppm', 'r.out.ppm3', 'r.out.vrml', 'r.out.vtk', 'r.out.xyz', 'r.param.scale', 'r.patch', 'r.path', 'r.path.coordinate.txt', 'r.plane', 'r.profile', 'r.proj', 'r.quant', 'r.quantile', 'r.quantile.plain', 'r.random', 'r.random.cells', 'r.random.surface', 'r.reclass', 'r.reclass.area', 'r.recode', 'r.regression.line', 'r.regression.multi', 'r.relief', 'r.relief.scaling', 'r.report', 'r.resamp.bspline', 'r.resamp.filter', 'r.resamp.interp', 'r.resamp.rst', 'r.resamp.stats', 'r.resample', 'r.rescale', 'r.rescale.eq', 'r.rgb', 'r.ros', 'r.series', 'r.series.accumulate', 'r.series.interp', 'r.shade', 'r.sim.sediment', 'r.sim.water', 'r.slope.aspect', 'r.solute.transport', 'r.spread', 'r.spreadpath', 'r.statistics', 'r.stats', 'r.stats.quantile.out', 'r.stats.quantile.rast', 'r.stats.zonal', 'r.stream.extract', 'r.sun.incidout', 'r.sun.insoltime', 'r.sunhours', 'r.sunmask.datetime', 'r.sunmask.position', 'r.surf.area', 'r.surf.contour', 'r.surf.fractal', 'r.surf.gauss', 'r.surf.idw', 'r.surf.random', 'r.terraflow', 'r.texture', 'r.thin', 'r.tile', 'r.tileset', 'r.to.vect', 'r.topidx', 'r.topmodel', 'r.topmodel.topidxstats', 'r.transect', 'r.univar', 'r.uslek', 'r.usler', 'r.viewshed', 'r.volume', 'r.walk.coords', 'r.walk.points', 'r.walk.rast', 'r.water.outlet', 'r.watershed', 'r.what.color', 'r.what.coords', 'r.what.points', 'v.buffer', 'v.build.check', 'v.build.polylines', 'v.class', 'v.clean', 'v.cluster', 'v.db.select', 'v.decimate', 'v.delaunay', 'v.dissolve', 'v.distance', 'v.drape', 'v.edit', 'v.extract', 'v.extrude', 'v.generalize', 'v.hull', 'v.in.ascii', 'v.in.dxf', 'v.in.e00', 'v.in.geonames', 'v.in.lidar', 'v.in.lines', 'v.in.mapgen', 'v.in.wfs', 'v.info', 'v.kcv', 'v.kernel.rast', 'v.kernel.vector', 'v.lidar.correction', 'v.lidar.edgedetection', 'v.lidar.growing', 'v.mkgrid', 'v.neighbors', 'v.net', 'v.net.alloc', 'v.net.allpairs', 'v.net.bridge', 'v.net.centrality', 'v.net.components', 'v.net.connectivity', 'v.net.distance', 'v.net.flow', 'v.net.iso', 'v.net.nreport', 'v.net.path', 'v.net.report', 'v.net.salesman', 'v.net.spanningtree', 'v.net.steiner', 'v.net.timetable', 'v.net.visibility', 'v.normal', 'v.out.ascii', 'v.out.dxf', 'v.out.postgis', 'v.out.pov', 'v.out.svg', 'v.out.vtk', 'v.outlier', 'v.overlay', 'v.pack', 'v.parallel', 'v.patch', 'v.perturb', 'v.proj', 'v.qcount', 'v.random', 'v.rast.stats', 'v.reclass', 'v.rectify', 'v.report', 'v.sample', 'v.segment', 'v.select', 'v.split', 'v.surf.bspline', 'v.surf.idw', 'v.surf.rst', 'v.surf.rst.cvdev', 'v.to.3d', 'v.to.lines', 'v.to.points', 'v.to.rast', 'v.transform', 'v.type', 'v.univar', 'v.vect.stats', 'v.voronoi', 'v.voronoi.skeleton', 'v.what.rast', 'v.what.vect', 'Add autoincremental field', 'Add field to attributes table', 'Add unique value index field', 'Add X/Y fields to layer', 'Affine transform', 'Aggregate', 'Align rasters', 'Align raster', 'Align points to features', 'Geodesic line split at antimeridian', 'Array of offset (parallel) lines', 'Array of translated features', 'Aspect', 'Assign projection', 'Export atlas layout as image', 'Export atlas layout as PDF (multiple files)', 'Export atlas layout as PDF (single file)', 'Convert B3DM to GLTF', 'Batch Nominatim geocoder', 'Convert spatial bookmarks to layer', 'Boundary', 'Bounding boxes', 'Buffer', 'Variable width buffer (by M value)', 'Calculate expression', 'Overlap analysis', 'Create categorized renderer from styles', 'Cell stack percentile', 'Cell stack percentrank from raster layer', 'Cell stack percent rank from value', 'Cell statistics', 'Centroids', 'Clip', 'Collect geometries', 'Combine style databases', 'Concave hull', 'Conditional branch', 'Convert GPS data', 'Convert GPX feature type', 'Convert to curved geometries', 'Convex hull', 'Count points in polygon', 'Create attribute index', 'Create constant raster layer', 'Create directory', 'Create grid', 'Create points layer from table', 'Create random raster layer (binomial distribution)', 'Create random raster layer (exponential distribution)', 'Create random raster layer (gamma distribution)', 'Create random raster layer (geometric distribution)', 'Create random raster layer (negative binomial distribution)', 'Create random raster layer (normal distribution)', 'Create random raster layer (poisson distribution)', 'Create random raster layer (uniform distribution)', 'Create spatial index', 'DBSCAN clustering', 'Delaunay triangulation', 'Drop field(s)', 'Delete duplicate geometries', 'Delete holes', 'Densify by count', 'Densify by interval', 'Detect dataset changes', 'Difference', 'Dissolve', 'Download GPS data from device', 'Download vector tiles', 'Drop geometries', 'Drop M/Z values', 'DTM filter (slope-based)', 'Export layers to DXF', 'Equal to frequency', 'Explode HStore Field', 'Explode lines', 'Export layer(s) information', 'Export mesh edges', 'Export mesh faces', 'Export mesh on grid', 'Export mesh vertices', 'Export to spreadsheet', 'Extend lines', 'Create layer from extent', 'Extract binary field', 'Extract by attribute', 'Extract by expression', 'Extract/clip by extent', 'Extract by location', 'Extract labels', 'Extract M values', 'Extract specific vertices', 'Extract vertices', 'Extract within distance', 'Extract Z values', 'Field calculator', 'Download file', 'Fill NoData cells', 'Feature filter', 'Filter by geometry type', 'Filter layers by type', 'Filter vertices by M value', 'Filter vertices by Z value', 'Fix geometries', 'Flatten relationship', 'Force right-hand-rule', 'Fuzzify raster (gaussian membership)', 'Fuzzify raster (large membership)', 'Fuzzify raster (linear membership)', 'Fuzzify raster (near membership)', 'Fuzzify raster (power membership)', 'Fuzzify raster (small membership)', 'Generate points (pixel centroids) inside polygons', 'Geometry by expression', 'Convert GLTF to vector features', 'Greater than frequency', 'Highest position in raster stack', 'Hillshade', 'Join by lines (hub lines)', 'Export to PostgreSQL', 'Import geotagged photos', 'Interpolate point on line', 'Intersection', 'Join attributes by location', 'Join attributes by field value', 'Join attributes by location (summary)', 'Join attributes by nearest', 'Keep N biggest parts', 'K-means clustering', 'Convert layer to spatial bookmarks', 'Less than frequency', 'Line density', 'Line intersections', 'Line substring', 'Load layer into project', 'Lowest position in raster stack', 'Mean coordinate(s)', 'Merge lines', 'Merge vector layers', 'Export contours', 'Export cross section dataset values on lines from mesh', 'Export time series values from points of a mesh dataset', 'Rasterize mesh dataset', 'Minimum enclosing circles', 'Raster calculator', 'Raster calculator (virtual)', 'Difference (multiple)', 'Intersection (multiple)', 'Multipart to singleparts', 'Multi-ring buffer (constant distance)', 'Union (multiple)', 'Nearest neighbour analysis', 'Offset lines', 'Order by expression', 'Oriented minimum bounding box', 'Orthogonalize', 'Package layers', 'Raster pixels to points', 'Raster pixels to polygons', 'Point on surface', 'Points along geometry', 'Points to path', 'Create layer from point', 'Pole of inaccessibility', 'Extract layer extent', 'Polygonize', 'Polygons to lines', 'PostgreSQL execute SQL', 'Print layout map extent to layer', 'Export print layout as image', 'Export print layout as PDF', 'Project points (Cartesian)', 'Promote to multipart', 'Raise exception', 'Raise message', 'Raise warning', 'Random extract', 'Random points in extent', 'Random points in polygons', 'Random points on lines', 'Raster boolean AND', 'Raster calculator', 'Convert map to raster', 'Raster layer properties', 'Raster layer statistics', 'Raster layer unique values report', 'Raster layer zonal statistics', 'Raster boolean OR', 'Sample raster values', 'Raster surface volume', 'Reclassify by layer', 'Reclassify by table', 'Rectangles, ovals, diamonds', 'Refactor fields', 'Delete duplicates by attribute', 'Remove duplicate vertices', 'Remove null geometries', 'Rename layer', 'Rename field', 'Repair Shapefile', 'Reproject layer', 'Rescale raster', 'Retain fields', 'Reverse line direction', 'Rotate', 'Roundness', 'Round raster', 'Ruggedness index', 'Save vector features to file', 'Save log to file', 'Extract selected features', 'Segmentize by maximum angle', 'Segmentize by maximum distance', 'Select by location', 'Select within distance', 'Service area (from layer)', 'Service area (from point)', 'Set layer encoding', 'Set layer style', 'Set M value from raster', 'Set M value', 'Set project variable', 'Drape (set Z value from raster)', 'Set Z value', 'Shortest line between features', 'Shortest path (layer to point)', 'Shortest path (point to layer)', 'Shortest path (point to point)', 'Extract Shapefile encoding', 'Simplify', 'Single sided buffer', 'Slope', 'Smooth', 'Snap geometries to layer', 'Snap points to grid', 'SpatiaLite execute SQL', 'SpatiaLite execute SQL (registered DB)', 'Split features by character', 'Split lines by maximum length', 'Split vector layer', 'Split with lines', 'ST-DBSCAN clustering', 'String concatenation', 'Create style database from project', 'Subdivide', 'Sum line lengths', 'Swap X and Y coordinates', 'Symmetrical difference', 'Tapered buffers', 'Generate XYZ tiles (Directory)', 'Generate XYZ tiles (MBTiles)', 'TIN Mesh Creation', 'Transect', 'Transfer annotations from main layer', 'Translate', 'Truncate table', 'Union', 'Upload GPS data to device', 'Raster calculator (virtual)', 'Voronoi polygons', 'Create wedge buffers', 'Write Vector Tiles (MBTiles)', 'Write Vector Tiles (XYZ)', 'Zonal histogram', 'Zonal statistics (in place)', 'Zonal statistics', 'Assign projection', 'Boundary', 'Clip', 'Convert format', 'Create COPC', 'Density', 'Export to raster', 'Export to raster (using triangulation)', 'Export to vector', 'Filter', 'Information', 'Merge', 'Reproject', 'Thin (by skipping points)', 'Thin (by sampling radius)', 'Tile', 'Build virtual point cloud (VPC)', 'Advanced Python field calculator', 'Bar plot', 'Basic statistics for fields', 'Box plot', 'Check validity', 'Climb along line', 'Convert geometry type', 'Define Shapefile projection', 'Distance matrix', 'Distance to nearest hub (line to hub)', 'Distance to nearest hub (points)', 'Eliminate selected polygons', 'Execute SQL', 'Add geometry attributes', 'Find projection', 'Generate points (pixel centroids) along line', 'Heatmap (Kernel Density Estimation)', 'Hypsometric curves', 'IDW interpolation', 'Export to SpatiaLite', 'Concave hull (k-nearest neighbor)', 'Lines to polygons', 'List unique values', 'Mean and standard deviation plot', 'Minimum bounding geometry', 'Points displacement', 'Polar plot', 'PostgreSQL execute and load SQL', 'Random extract within subsets', 'Random points along line', 'Random points in layer bounds', 'Random points inside polygons', 'Random selection', 'Random selection within subsets', 'Raster calculator', 'Raster layer histogram', 'Rectangles, ovals, diamonds (variable)', 'Regular points', 'Relief', 'Vector layer scatterplot 3D', 'Select by attribute', 'Select by expression', 'Set style for raster layer', 'Set style for vector layer', 'Statistics by categories', 'Text to float', 'TIN interpolation', 'Topological coloring', 'Variable distance buffer', 'Vector layer histogram', 'Vector layer scatterplot']\n",
    "len(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b386474-476e-406e-a3e6-ae0dd10bf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRASS_tools =[\"g.extension.list\", \"g.extension.manage\", \"i.albedo\", \"i.aster.toar\", \"i.atcorr\", \"i.biomass\", \"i.cca\", \"i.cluster\", \"i.colors.enhance\", \"i.eb.eta\", \"i.eb.evapfr\", \"i.eb.hsebal01.coords\", \"i.eb.netrad\", \"i.eb.soilheatflux\", \"i.emissivity\", \"i.evapo.mh\", \"i.evapo.pm\", \"i.evapo.pt\", \"i.evapo.time\", \"i.fft\", \"i.gensig\", \"i.gensigset\", \"i.group\", \"i.his.rgb\", \"i.ifft\", \"i.image.mosaic\", \"i.in.spotvgt\", \"i.landsat.acca\", \"i.landsat.toar\", \"i.maxlik\", \"i.modis.qc\", \"i.oif\", \"i.pansharpen\", \"i.pca\", \"i.rgb.his\", \"i.segment\", \"i.smap\", \"i.tasscap\", \"i.topo.coor.ill\", \"i.topo.corr\", \"i.vi\", \"i.zc\", \"m.cogo\", \"nviz\", \"r.basins.fill\", \"r.blend.combine\", \"r.blend.rgb\", \"r.buffer\", \"r.buffer.lowmem\", \"r.carve\", \"r.category\", \"r.category.out\", \"r.circle\", \"r.clump\", \"r.coin\", \"r.colors\", \"r.colors.out\", \"r.colors.stddev\", \"r.composite\", \"r.contour\", \"r.cost\", \"r.covar\", \"r.cross\", \"r.describe\", \"r.distance\", \"r.drain\", \"r.fill.dir\", \"r.fill.stats\", \"r.fillnulls\", \"r.flow\", \"r.geomorphon\", \"r.grow\", \"r.grow.distance\", \"r.gwflow\", \"r.his\", \"r.horizon\", \"r.horizon.height\", \"r.in.lidar\", \"r.in.lidar.info\", \"r.info\", \"r.kappa\", \"r.lake\", \"r.latlong\", \"r.li.cwed\", \"r.li.cwed.ascii\", \"r.li.dominance\", \"r.li.dominance.ascii\", \"r.li.edgedensity\", \"r.li.edgedensity.ascii\", \"r.li.mpa\", \"r.li.mpa.ascii\", \"r.li.mps\", \"r.li.mps.ascii\", \"r.li.padcv\", \"r.li.padcv.ascii\", \"r.li.padrange\", \"r.li.padrange.ascii\", \"r.li.padsd\", \"r.li.padsd.ascii\", \"r.li.patchdensity\", \"r.li.patchdensity.ascii\", \"r.li.patchnum\", \"r.li.patchnum.ascii\", \"r.li.pielou\", \"r.li.pielou.ascii\", \"r.li.renyi\", \"r.li.renyi.ascii\", \"r.li.richness\", \"r.li.richness.ascii\", \"r.li.shannon\", \"r.li.shannon.ascii\", \"r.li.shape\", \"r.li.shape.ascii\", \"r.li.simpson\", \"r.li.simpson.ascii\", \"r.mapcalc.simple\", \"r.mask.rast\", \"r.mask.vect\", \"r.mfilter\", \"r.mode\", \"r.neighbors\", \"r.null\", \"r.out.ascii\", \"r.out.gridatb\", \"r.out.mat\", \"r.out.mpeg\", \"r.out.png\", \"r.out.pov\", \"r.out.ppm\", \"r.out.ppm3\", \"r.out.vrml\", \"r.out.vtk\", \"r.out.xyz\", \"r.param.scale\", \"r.patch\", \"r.path\", \"r.path.coordinate.txt\", \"r.plane\", \"r.profile\", \"r.proj\", \"r.quant\", \"r.quantile\", \"r.quantile.plain\", \"r.random\", \"r.random.cells\", \"r.random.surface\", \"r.reclass\", \"r.reclass.area\", \"r.recode\", \"r.regression.line\", \"r.regression.multi\", \"r.relief\", \"r.relief.scaling\", \"r.report\", \"r.resamp.bspline\", \"r.resamp.filter\", \"r.resamp.interp\", \"r.resamp.rst\", \"r.resamp.stats\", \"r.resample\", \"r.rescale\", \"r.rescale.eq\", \"r.rgb\", \"r.ros\", \"r.series\", \"r.series.accumulate\", \"r.series.interp\", \"r.shade\", \"r.sim.sediment\", \"r.sim.water\", \"r.slope.aspect\", \"r.solute.transport\", \"r.spread\", \"r.spreadpath\", \"r.statistics\", \"r.stats\", \"r.stats.quantile.out\", \"r.stats.quantile.rast\", \"r.stats.zonal\", \"r.stream.extract\", \"r.sun.incidout\", \"r.sun.insoltime\", \"r.sunhours\", \"r.sunmask.datetime\", \"r.sunmask.position\", \"r.surf.area\", \"r.surf.contour\", \"r.surf.fractal\", \"r.surf.gauss\", \"r.surf.idw\", \"r.surf.random\", \"r.terraflow\", \"r.texture\", \"r.thin\", \"r.tile\", \"r.tileset\", \"r.to.vect\", \"r.topidx\", \"r.topmodel\", \"r.topmodel.topidxstats\", \"r.transect\", \"r.univar\", \"r.uslek\", \"r.usler\", \"r.viewshed\", \"r.volume\", \"r.walk.coords\", \"r.walk.points\", \"r.walk.rast\", \"r.water.outlet\", \"r.watershed\", \"r.what.color\", \"r.what.coords\", \"r.what.points\", \"v.buffer\", \"v.build.check\", \"v.build.polylines\", \"v.class\", \"v.clean\", \"v.cluster\", \"v.db.select\", \"v.decimate\", \"v.delaunay\", \"v.dissolve\", \"v.distance\", \"v.drape\", \"v.edit\", \"v.extract\", \"v.extrude\", \"v.generalize\", \"v.hull\", \"v.in.ascii\", \"v.in.dxf\", \"v.in.e00\", \"v.in.geonames\", \"v.in.lidar\", \"v.in.lines\", \"v.in.mapgen\", \"v.in.wfs\", \"v.info\", \"v.kcv\", \"v.kernel.rast\", \"v.kernel.vector\", \"v.lidar.correction\", \"v.lidar.edgedetection\", \"v.lidar.growing\", \"v.mkgrid\", \"v.neighbors\", \"v.net\", \"v.net.alloc\", \"v.net.allpairs\", \"v.net.bridge\", \"v.net.centrality\", \"v.net.components\", \"v.net.connectivity\", \"v.net.distance\", \"v.net.flow\", \"v.net.iso\", \"v.net.nreport\", \"v.net.path\", \"v.net.report\", \"v.net.salesman\", \"v.net.spanningtree\", \"v.net.steiner\", \"v.net.timetable\", \"v.net.visibility\", \"v.normal\", \"v.out.ascii\", \"v.out.dxf\", \"v.out.postgis\", \"v.out.pov\", \"v.out.svg\", \"v.out.vtk\", \"v.outlier\", \"v.overlay\", \"v.pack\", \"v.parallel\", \"v.patch\", \"v.perturb\", \"v.proj\", \"v.qcount\", \"v.random\", \"v.rast.stats\", \"v.reclass\", \"v.rectify\", \"v.report\", \"v.sample\", \"v.segment\", \"v.select\", \"v.split\", \"v.surf.bspline\", \"v.surf.idw\", \"v.surf.rst\", \"v.surf.rst.cvdev\", \"v.to.3d\", \"v.to.lines\", \"v.to.points\", \"v.to.rast\", \"v.transform\", \"v.type\", \"v.univar\", \"v.vect.stats\", \"v.voronoi\", \"v.voronoi.skeleton\", \"v.what.rast\", \"v.what.vect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa4119-f97d-4e4e-9cb4-9d3c00cd382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in GRASS_tools:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99490b-4f99-498f-9792-b615e19cfcf4",
   "metadata": {},
   "source": [
    "# Grass Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a45e7-1db6-45fc-8f70-3adfad6e9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRASS_tools =[\"g.extension.list\", \"g.extension.manage\", \"i.albedo\", \"i.aster.toar\", \"i.atcorr\", \"i.biomass\", \"i.cca\", \"i.cluster\", \"i.colors.enhance\", \"i.eb.eta\", \"i.eb.evapfr\", \"i.eb.hsebal01.coords\", \"i.eb.netrad\", \"i.eb.soilheatflux\", \"i.emissivity\", \"i.evapo.mh\", \"i.evapo.pm\", \"i.evapo.pt\", \"i.evapo.time\", \"i.fft\", \"i.gensig\", \"i.gensigset\", \"i.group\", \"i.his.rgb\", \"i.ifft\", \"i.image.mosaic\", \"i.in.spotvgt\", \"i.landsat.acca\", \"i.landsat.toar\", \"i.maxlik\", \"i.modis.qc\", \"i.oif\", \"i.pansharpen\", \"i.pca\", \"i.rgb.his\", \"i.segment\", \"i.smap\", \"i.tasscap\", \"i.topo.coor.ill\", \"i.topo.corr\", \"i.vi\", \"i.zc\", \"m.cogo\", \"nviz\", \"r.basins.fill\", \"r.blend.combine\", \"r.blend.rgb\", \"r.buffer\", \"r.buffer.lowmem\", \"r.carve\", \"r.category\", \"r.category.out\", \"r.circle\", \"r.clump\", \"r.coin\", \"r.colors\", \"r.colors.out\", \"r.colors.stddev\", \"r.composite\", \"r.contour\", \"r.cost\", \"r.covar\", \"r.cross\", \"r.describe\", \"r.distance\", \"r.drain\", \"r.fill.dir\", \"r.fill.stats\", \"r.fillnulls\", \"r.flow\", \"r.geomorphon\", \"r.grow\", \"r.grow.distance\", \"r.gwflow\", \"r.his\", \"r.horizon\", \"r.horizon.height\", \"r.in.lidar\", \"r.in.lidar.info\", \"r.info\", \"r.kappa\", \"r.lake\", \"r.latlong\", \"r.li.cwed\", \"r.li.cwed.ascii\", \"r.li.dominance\", \"r.li.dominance.ascii\", \"r.li.edgedensity\", \"r.li.edgedensity.ascii\", \"r.li.mpa\", \"r.li.mpa.ascii\", \"r.li.mps\", \"r.li.mps.ascii\", \"r.li.padcv\", \"r.li.padcv.ascii\", \"r.li.padrange\", \"r.li.padrange.ascii\", \"r.li.padsd\", \"r.li.padsd.ascii\", \"r.li.patchdensity\", \"r.li.patchdensity.ascii\", \"r.li.patchnum\", \"r.li.patchnum.ascii\", \"r.li.pielou\", \"r.li.pielou.ascii\", \"r.li.renyi\", \"r.li.renyi.ascii\", \"r.li.richness\", \"r.li.richness.ascii\", \"r.li.shannon\", \"r.li.shannon.ascii\", \"r.li.shape\", \"r.li.shape.ascii\", \"r.li.simpson\", \"r.li.simpson.ascii\", \"r.mapcalc.simple\", \"r.mask.rast\", \"r.mask.vect\", \"r.mfilter\", \"r.mode\", \"r.neighbors\", \"r.null\", \"r.out.ascii\", \"r.out.gridatb\", \"r.out.mat\", \"r.out.mpeg\", \"r.out.png\", \"r.out.pov\", \"r.out.ppm\", \"r.out.ppm3\", \"r.out.vrml\", \"r.out.vtk\", \"r.out.xyz\", \"r.param.scale\", \"r.patch\", \"r.path\", \"r.path.coordinate.txt\", \"r.plane\", \"r.profile\", \"r.proj\", \"r.quant\", \"r.quantile\", \"r.quantile.plain\", \"r.random\", \"r.random.cells\", \"r.random.surface\", \"r.reclass\", \"r.reclass.area\", \"r.recode\", \"r.regression.line\", \"r.regression.multi\", \"r.relief\", \"r.relief.scaling\", \"r.report\", \"r.resamp.bspline\", \"r.resamp.filter\", \"r.resamp.interp\", \"r.resamp.rst\", \"r.resamp.stats\", \"r.resample\", \"r.rescale\", \"r.rescale.eq\", \"r.rgb\", \"r.ros\", \"r.series\", \"r.series.accumulate\", \"r.series.interp\", \"r.shade\", \"r.sim.sediment\", \"r.sim.water\", \"r.slope.aspect\", \"r.solute.transport\", \"r.spread\", \"r.spreadpath\", \"r.statistics\", \"r.stats\", \"r.stats.quantile.out\", \"r.stats.quantile.rast\", \"r.stats.zonal\", \"r.stream.extract\", \"r.sun.incidout\", \"r.sun.insoltime\", \"r.sunhours\", \"r.sunmask.datetime\", \"r.sunmask.position\", \"r.surf.area\", \"r.surf.contour\", \"r.surf.fractal\", \"r.surf.gauss\", \"r.surf.idw\", \"r.surf.random\", \"r.terraflow\", \"r.texture\", \"r.thin\", \"r.tile\", \"r.tileset\", \"r.to.vect\", \"r.topidx\", \"r.topmodel\", \"r.topmodel.topidxstats\", \"r.transect\", \"r.univar\", \"r.uslek\", \"r.usler\", \"r.viewshed\", \"r.volume\", \"r.walk.coords\", \"r.walk.points\", \"r.walk.rast\", \"r.water.outlet\", \"r.watershed\", \"r.what.color\", \"r.what.coords\", \"r.what.points\", \"v.buffer\", \"v.build.check\", \"v.build.polylines\", \"v.class\", \"v.clean\", \"v.cluster\", \"v.db.select\", \"v.decimate\", \"v.delaunay\", \"v.dissolve\", \"v.distance\", \"v.drape\", \"v.edit\", \"v.extract\", \"v.extrude\", \"v.generalize\", \"v.hull\", \"v.in.ascii\", \"v.in.dxf\", \"v.in.e00\", \"v.in.geonames\", \"v.in.lidar\", \"v.in.lines\", \"v.in.mapgen\", \"v.in.wfs\", \"v.info\", \"v.kcv\", \"v.kernel.rast\", \"v.kernel.vector\", \"v.lidar.correction\", \"v.lidar.edgedetection\", \"v.lidar.growing\", \"v.mkgrid\", \"v.neighbors\", \"v.net\", \"v.net.alloc\", \"v.net.allpairs\", \"v.net.bridge\", \"v.net.centrality\", \"v.net.components\", \"v.net.connectivity\", \"v.net.distance\", \"v.net.flow\", \"v.net.iso\", \"v.net.nreport\", \"v.net.path\", \"v.net.report\", \"v.net.salesman\", \"v.net.spanningtree\", \"v.net.steiner\", \"v.net.timetable\", \"v.net.visibility\", \"v.normal\", \"v.out.ascii\", \"v.out.dxf\", \"v.out.postgis\", \"v.out.pov\", \"v.out.svg\", \"v.out.vtk\", \"v.outlier\", \"v.overlay\", \"v.pack\", \"v.parallel\", \"v.patch\", \"v.perturb\", \"v.proj\", \"v.qcount\", \"v.random\", \"v.rast.stats\", \"v.reclass\", \"v.rectify\", \"v.report\", \"v.sample\", \"v.segment\", \"v.select\", \"v.split\", \"v.surf.bspline\", \"v.surf.idw\", \"v.surf.rst\", \"v.surf.rst.cvdev\", \"v.to.3d\", \"v.to.lines\", \"v.to.points\", \"v.to.rast\", \"v.transform\", \"v.type\", \"v.univar\", \"v.vect.stats\", \"v.voronoi\", \"v.voronoi.skeleton\", \"v.what.rast\", \"v.what.vect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a664c-8260-4f90-9e6b-5f095baefda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, tool in enumerate(GRASS_tools):\n",
    "    print(f\"Processing: {idx + 1} / {len(GRASS_tools)}, {t} \")\n",
    "    url = f\"https://grass.osgeo.org/grass84/manuals/{tool}.html\"\n",
    "    print(\"    URL:\", url)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    \n",
    "    if idx > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e8752-8a9f-4db7-b2c6-79d8025ed579",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_response(url)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d92b1a-7a8f-4893-8d21-0c1953c166db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# Sample HTML (In a real case, you would read this from an HTML file)\n",
    " \n",
    "\n",
    "# Parse the HTML content\n",
    "# soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Dictionary to hold headers and associated text content\n",
    "content_dict = {}\n",
    "\n",
    "# Function to assemble text under each header, including non-tag inline text\n",
    "def get_associated_content(header):\n",
    "    content = []\n",
    "    next_sibling = header.find_next_sibling()\n",
    "\n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        # Handle elements with tags\n",
    "        if next_sibling.name in ['a', 'p', 'em', 'div',  'b', 'dd', 'dt', 'dl']:\n",
    "            content.append(next_sibling.get_text(strip=True))\n",
    "        # Handle inline text outside of tags\n",
    "        if next_sibling.next_sibling and isinstance(next_sibling.next_sibling, str):\n",
    "            content.append(next_sibling.next_sibling.strip())\n",
    "        next_sibling = next_sibling.find_next_sibling()\n",
    "\n",
    "    # Join everything together in paragraph form\n",
    "    return ' '.join(content)\n",
    "\n",
    "# Extract headers and assemble content for each section\n",
    "for header in soup.find_all(['h2', 'h3', 'h4']):\n",
    "    header_text = header.get_text(strip=True)\n",
    "    paragraph = get_associated_content(header)\n",
    "    if paragraph:\n",
    "        content_dict[header_text] = paragraph\n",
    "\n",
    "# Save the result to a JSON file\n",
    "with open('assembled_content.json', 'w') as json_file:\n",
    "    json.dump(content_dict, json_file, indent=4)\n",
    "\n",
    "print(\"Content assembled and saved to assembled_content.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eac71f-9326-4263-b6d0-264d07e5d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "soup = get_response(url)\n",
    "\n",
    "# Dictionary to hold headers and associated paragraphs\n",
    "content_dict = {}\n",
    "\n",
    "# Function to assemble text under each header, including non-tag inline text\n",
    "def get_associated_content(header):\n",
    "    content = []\n",
    "    next_sibling = header.find_next_sibling()\n",
    "    \n",
    "    # print(\"next_sibling:\", next_sibling)\n",
    "\n",
    "    # Loop through sibling elements until another header tag is encountered\n",
    "#     while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "#         # Handle elements with tags\n",
    "#         if next_sibling and next_sibling.name in ['a', 'p', 'div', 'em', 'b', 'dd', 'dt']:\n",
    "#             content.append(next_sibling.get_text(strip=True))\n",
    "#         # Handle inline text outside of tags\n",
    "#         if next_sibling and isinstance(next_sibling, str):\n",
    "#             content.append(next_sibling.strip(strip=True))\n",
    "#         # Move to the next sibling (tag or text node)\n",
    "#         next_sibling = next_sibling.find_next_sibling()\n",
    "        \n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        # Handle elements with tags\n",
    "        if next_sibling.name in ['a', 'p', 'em', 'div',  'b', 'dd', 'dt', 'dl']:\n",
    "            content.append(next_sibling.get_text(strip=True))\n",
    "        # Handle inline text outside of tags\n",
    "        if next_sibling.next_sibling and isinstance(next_sibling.next_sibling, str):\n",
    "            content.append(next_sibling.next_sibling.strip())\n",
    "        next_sibling = next_sibling.find_next_sibling()\n",
    "\n",
    "\n",
    "    # Join everything together in paragraph form\n",
    "    return ' '.join(content)\n",
    "\n",
    "# Variables to store current hierarchy level\n",
    "current_h2 = None\n",
    "current_h3 = None\n",
    "\n",
    "# Extract headers (h2, h3, h4) and their associated paragraphs\n",
    "# Iterate through all headers (h2, h3, h4)\n",
    "for header in soup.find_all(['h2', 'h3', 'h4']):\n",
    "    header_text = header.get_text(strip=True)\n",
    "    paragraph = get_associated_content(header)\n",
    "    \n",
    "    # print(\"header.name:\", header.name, header_text)\n",
    "    # print(\"paragraph:\", paragraph)\n",
    "    \n",
    "    if header.name == 'h2':\n",
    "        # Create a new h2 entry\n",
    "        content_dict[header_text] = {}\n",
    "        current_h2 = header_text\n",
    "        current_h3 = None  # Reset h3 context\n",
    "        content_dict[current_h2] = {}\n",
    "        content_dict[current_h2]['paragraphs'] = paragraph\n",
    "        print(\"header.name:\", header.name, current_h2)\n",
    "        # print(\"paragraph:\", paragraph)\n",
    "\n",
    "    elif header.name == 'h3' and current_h2:\n",
    "        # Create a new h3 entry under the current h2\n",
    "        # content_dict[current_h2][header_text] = {}\n",
    "        current_h3 = header_text\n",
    "        # print(\"content_dict:\", content_dict[current_h2])\n",
    "        print(\"header.name:\", header.name, current_h3)\n",
    "        content_dict[current_h2][current_h3] = paragraph\n",
    "\n",
    "#     elif header.name == 'h4' and current_h2 and current_h3:\n",
    "#         # Create a new h4 entry under the current h3\n",
    "#         content_dict[current_h2][current_h3][header_text] = paragraph\n",
    "\n",
    "# for header in soup.find_all(['h2', 'h3', 'h4']):\n",
    "#     header_text = header.get_text(strip=True)\n",
    "#     paragraph = get_associated_content(header)\n",
    "#     if paragraph:\n",
    "#         content_dict[header_text] = paragraph\n",
    "\n",
    "        \n",
    "# Save the result to a JSON file\n",
    "with open('headers_and_paragraphs.json', 'w') as json_file:\n",
    "    json.dump(content_dict, json_file, indent=4)\n",
    "\n",
    "print(\"Headers and paragraphs extracted and saved to headers_and_paragraphs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2557e5-6c62-4559-9a8c-9ec5a2e20af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "# Function to assemble text under each header, including non-tag inline text\n",
    "def get_associated_content(header):\n",
    "    content = []\n",
    "    next_sibling = header.find_next_sibling()\n",
    "\n",
    "    # Loop through sibling elements until another header tag (h2, h3, h4) is encountered\n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        # Handle elements with tags\n",
    "        if next_sibling.name in ['a', 'p', 'div', 'em', 'b', 'dd', 'dt']:\n",
    "            content.append(next_sibling.get_text(strip=True))\n",
    "        # Handle inline text outside of tags\n",
    "        if next_sibling.next_sibling and isinstance(next_sibling.next_sibling, str):\n",
    "            content.append(next_sibling.next_sibling.strip())\n",
    "        next_sibling = next_sibling.find_next_sibling()\n",
    "\n",
    "    # Join everything together in paragraph form\n",
    "    return ' '.join(content)\n",
    "\n",
    "# Recursive function to process headers and their subheaders\n",
    "def process_headers(header):\n",
    "    result = {}\n",
    "    header_text = header.get_text(strip=True)\n",
    "    paragraph = get_associated_content(header)\n",
    "\n",
    "    # Store the paragraph content\n",
    "    result[\"content\"] = paragraph\n",
    "\n",
    "    # Recursively process subheaders\n",
    "    next_sibling = header.find_next_sibling()\n",
    "    while next_sibling and next_sibling.name != 'h2':  # Stop when encountering the next h2 header\n",
    "        if next_sibling.name == 'h3':\n",
    "            result[next_sibling.get_text(strip=True)] = process_headers(next_sibling)\n",
    "        if next_sibling.name == 'h4':\n",
    "            result[next_sibling.get_text(strip=True)] = process_headers(next_sibling)\n",
    "        next_sibling = next_sibling.find_next_sibling()\n",
    "\n",
    "    return result\n",
    "\n",
    "# Main dictionary to store all headers and subheaders\n",
    "content_dict = {}\n",
    "\n",
    "# Extract and process all h2 headers and recursively process their subheaders\n",
    "for header in soup.find_all('h2'):\n",
    "    content_dict[header.get_text(strip=True)] = process_headers(header)\n",
    "\n",
    "# Save the result to a JSON file\n",
    "with open('headers_and_subheaders_recursive.json', 'w') as json_file:\n",
    "    json.dump(content_dict, json_file, indent=4)\n",
    "\n",
    "print(\"Headers and subheaders extracted and saved to headers_and_subheaders_recursive.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbb895-50f3-4dae-b619-7da982c56b01",
   "metadata": {},
   "source": [
    "# By header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "558f3bfa-59bf-4bd2-be2c-4a141cf50552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  i.aster.toar - GRASS GIS manual\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import copy\n",
    "import pprint\n",
    "\n",
    "url = r'https://grass.osgeo.org/grass84/manuals/i.aster.toar.html'\n",
    "\n",
    "soup = get_response(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b92b4485-2514-407e-84d1-99f588a4583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "KEYWORDS\n",
      "SYNOPSIS\n",
      "Flags:\n",
      "Parameters:\n",
      "Table of contents\n",
      "DESCRIPTION\n",
      "NOTES\n",
      "SEE ALSO\n",
      "AUTHOR\n",
      "SOURCE CODE\n",
      "{'Flags': {'--help': 'Print usage summary', '--overwrite': 'Allow output files to overwrite existing files', '--quiet': 'Quiet module output', '--ui': 'Force launching GUI dialog', '--verbose': 'Verbose module output', '-a': 'VNIR is High Gain', '-b': 'SWIR is High Gain', '-c': 'VNIR is Low Gain 1', '-d': 'SWIR is Low Gain 1', '-e': 'SWIR is Low Gain 2', '-r': 'Output is radiance (W/m2)'},\n",
      " 'brief_description': 'Calculates Top of Atmosphere Radiance/Reflectance/Brightness Temperature from ASTER DN.',\n",
      " 'description': ['i.aster.toar calculates the Top Of Atmosphere (TOA) reflectancefor Terra-ASTER L1B in the visible, NIR and SWIR bands (9+1 bands) andbrightness temperature for the TIR bands (5 bands), all from L1B DN values.It is useful to apply after import of original ASTER imagery thatis generally in standard DN values range.', 'The order of input bands is', 'â€¢ VNIR: 1,2,3N,3B', 'â€¢ SWIR: 4,5,6,7,8,9', 'â€¢ TIR: 10,11,12,13,14', 'in one comma-separated list.'],\n",
      " 'keywords': ['imagery', 'radiometric conversion', 'radiance', 'reflectance', 'brightness temperature', 'satellite', 'ASTER'],\n",
      " 'name': 'i.aster.toar',\n",
      " 'notes': ['Internally, a gain code is defined to modify gains according to spectralbands following the GeoSystems GmbH ATCOR Ver. 2.0 Calibration Files.The function is defined in gain_aster.c file.', '/*Gain Code*/\\n    /*0 - High (Not Applicable for band 10-14: TIR)*/\\n    /*1 - Normal*/\\n    /*2 - Low 1(Not Applicable for band 10-14: TIR)*/\\n    /*3 - Low 2(Not Applicable for Band 1-3N/B and 10-14)*/\\n', '', ''],\n",
      " 'see_also': ['i.landsat.toar', 'r.in.aster'],\n",
      " 'synopsis': ['i.aster.toar', 'i.aster.toar --help', 'i.aster.toar[-rabcde]input=name[,name,...]dayofyear=floatsun_elevation=floatoutput=name[--overwrite]  [--help]  [--verbose]  [--quiet]  [--ui]']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Dictionary to hold headers and their associated content\n",
    "content_dict = {}\n",
    "\n",
    "\n",
    "# grass_html = Extract_GRASS_doc(soup)\n",
    " \n",
    "\n",
    "def get_name_content(header, tool_info):\n",
    "    \n",
    "    next_sibling = header.find_next_sibling()\n",
    "    \n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        if next_sibling.name in ['a', 'p', 'em', 'div',  'b', 'dd', 'dt', 'dl', 'pre']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)\n",
    "            tool_info['name'] = sibling_text\n",
    "            \n",
    "        # Handle inline text outside of tags\n",
    "        if next_sibling.next_sibling and isinstance(next_sibling.next_sibling, str):\n",
    "            sibling_text = next_sibling.next_sibling.strip()\n",
    "            tool_info['brief_description'] = sibling_text[2:] # remove the starting \"- \". \n",
    "            \n",
    "        next_sibling = next_sibling.find_next_sibling()        \n",
    "             \n",
    "    return tool_info\n",
    "\n",
    "def get_keywords_content(header, tool_info):\n",
    "    keywords = []\n",
    "    next_sibling = header.find_next_sibling()\n",
    "    \n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        if next_sibling.name in ['a', 'p', 'em', 'div',  'b', 'dd', 'dt', 'dl', 'pre']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)            \n",
    "            keywords.append(sibling_text) \n",
    "            \n",
    "        next_sibling = next_sibling.find_next_sibling()  \n",
    "    tool_info['keywords'] = keywords\n",
    "             \n",
    "    return tool_info\n",
    "\n",
    "def get_synopsis_content(header, tool_info):\n",
    "    content_lines = []\n",
    "    \n",
    "    # get tool name\n",
    "    next_sibling = header.find_next_sibling()\n",
    "    sibling_text = next_sibling.get_text(strip=True)    \n",
    "    content_lines.append(sibling_text)\n",
    "    \n",
    "    # get tool --help\n",
    "    next_sibling = next_sibling.find_next_sibling()    \n",
    "    sibling_text = next_sibling.get_text(strip=True)    \n",
    "    content_lines.append(sibling_text)\n",
    "    \n",
    "    \n",
    "    next_sibling = next_sibling.find_next_sibling() # skip a <br>\n",
    "    \n",
    "    # get tool command    \n",
    "    next_sibling = next_sibling.find_next_sibling()    \n",
    "    sibling_text = next_sibling.get_text(strip=True)    \n",
    "    content_lines.append(sibling_text)\n",
    "     \n",
    "    tool_info['synopsis'] = content_lines\n",
    "             \n",
    "    return tool_info\n",
    "\n",
    "def get_flags_content(header, tool_info):\n",
    "    content_dict = {}    \n",
    "    next_sibling = header.find_next_sibling()  \n",
    "    dl = next_sibling.find('dl')\n",
    "    # Iterate over <dt> and <dd> tags\n",
    "    for dt in next_sibling.find_all('dt'):\n",
    "        term = dt.get_text(strip=True)  # Get the text in <dt>\n",
    "        dd = dt.find_next_sibling('dd')  # Get the corresponding <dd>\n",
    "        if dd:\n",
    "            description = dd.get_text(strip=True)  # Get the text in <dd>\n",
    "            content_dict[term] = description\n",
    "     \n",
    "    tool_info['Flags'] = content_dict\n",
    "             \n",
    "    return tool_info\n",
    "\n",
    "def get_parameters_content(header, tool_info):\n",
    "    content_dict = {}    \n",
    "    next_sibling = header.find_next_sibling()  \n",
    "    dl = next_sibling.find('dl')\n",
    "    # Iterate over <dt> and <dd> tags\n",
    "    for dt in next_sibling.find_all('dt'):\n",
    "        term = dt.get_text(strip=True)  # Get the text in <dt>\n",
    "        dd = dt.find_next_sibling('dd')  # Get the corresponding <dd>\n",
    "        if dd:\n",
    "            description = dd.get_text(strip=True)  # Get the text in <dd>\n",
    "            content_dict[term] = description\n",
    "     \n",
    "    tool_info['Parameters'] = content_dict\n",
    "             \n",
    "    return tool_info\n",
    "\n",
    "def get_description_content(header, tool_info):\n",
    "    paragraphs = []\n",
    "    paragarph = \"\"\n",
    "    next_sibling = header.next_sibling\n",
    "    # print(\"next_sibling:\", next_sibling.name, next_sibling.get_text(strip=True))\n",
    "    # print(\"next_sibling:\", next_sibling.name, next_sibling.get_text(strip=True))\n",
    "    \n",
    "    while next_sibling and next_sibling.name not in ['h2']:\n",
    "        if next_sibling.name in ['a', 'em', 'div',  'b', 'dd', 'dt', 'dl', 'pre']:\n",
    "            # print(\"next_sibling.name:\", next_sibling.name)\n",
    "            sibling_text = next_sibling.get_text(strip=True)            \n",
    "            paragarph += sibling_text            \n",
    "            # print(\"type of next_sibling:\", type(next_sibling))\n",
    "            # print(\"sibling_text:\", sibling_text)\n",
    "            \n",
    "        # if next_sibling.next_sibling and isinstance(next_sibling.next_sibling, str):\n",
    "        if isinstance(next_sibling, str):\n",
    "            sibling_text = next_sibling.get_text().replace('\\n', '')\n",
    "            \n",
    "            # print(\"      stringï¼Œ sibling_text:\", sibling_text)\n",
    "            \n",
    "            if next_sibling.next_sibling.name in [\"h2\", \"h3\", \"h4\"]:\n",
    "                paragraphs.append(sibling_text)\n",
    "                # print(\"paragraphs:\", paragraphs)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                paragarph += sibling_text\n",
    "            # print(\"stringï¼Œ sibling_text:\", sibling_text)\n",
    "            # print(\"type of next_sibling.next_sibling:\", type(next_sibling.next_sibling))\n",
    "            # print(\" next_sibling.next_sibling:\", next_sibling.next_sibling)\n",
    "             \n",
    "            # next_sibling.next_sibling\n",
    "            # print(\"next_sibling.name:\", next_sibling.name)\n",
    "            # print(\"paragraphs:\", paragraphs)\n",
    "            \n",
    "        if next_sibling.name in ['p']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)   \n",
    "            paragraphs.append(paragarph)\n",
    "            \n",
    "            # print(\"paragraphs:\", paragraphs)\n",
    "            # print(\"pï¼Œ paragarph:\", paragarph)\n",
    "            paragarph = \"\"\n",
    "            paragraphs.append(sibling_text)            \n",
    "            # print(\"sibling_text:\", sibling_text)\n",
    "            # print(\"paragraphs:\", paragraphs)\n",
    "            \n",
    "             \n",
    "        if next_sibling.name in ['ul']:\n",
    "            \n",
    "            if paragarph:\n",
    "                paragraphs.append(paragarph)\n",
    "                # print(\"paragraphs:\", paragraphs)\n",
    "                paragarph = \"\"\n",
    "            \n",
    "            sibling_text = next_sibling.get_text(strip=False)\n",
    "            ulist = sibling_text.split('\\n')\n",
    "            \n",
    "            # print(\"ulist:\", ulist            \n",
    "            # remove emptry strings\n",
    "            ulist = [f\"â€¢{item}\" for item in ulist if item]  # correct\n",
    "            # print(\"ulist:\", ulist)\n",
    "            # ulist = [ for item in ulist if item]\n",
    "            \n",
    "            # print(\"paragraphs:\", paragraphs)\n",
    "            \n",
    "            paragraphs += ulist\n",
    "            \n",
    "            # paragraphs.append(sibling_text)\n",
    "            # print(\"paragraphs:\", paragraphs)\n",
    "              \n",
    "        # next_sibling = next_sibling.find_next_sibling()  # cannot find strings that are not enclosed in tags\n",
    "        next_sibling = next_sibling.next_sibling  # can find strings that are not enclosed in tags\n",
    "        # print(\"next_sibling:\", next_sibling.name, next_sibling.get_text(strip=True))\n",
    "        \n",
    "        \n",
    "    tool_info['description'] = paragraphs\n",
    "             \n",
    "    return tool_info\n",
    " \n",
    "    \n",
    "def get_notes_content(header, tool_info):\n",
    "    paragraphs = []\n",
    "    paragarph = \"\"\n",
    "    next_sibling = header.next_sibling\n",
    "    # print(\"next_sibling:\", next_sibling.name, next_sibling.get_text(strip=True))\n",
    "    \n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        if next_sibling.name in ['a', 'em',  'b', 'dd', 'dt', 'dl']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)            \n",
    "            paragarph += sibling_text             \n",
    "            \n",
    "        if isinstance(next_sibling, str):\n",
    "            sibling_text = next_sibling.get_text().replace('\\n', '')\n",
    "            \n",
    "            # print(\"     string next_sibling:\", next_sibling.name, next_sibling.get_text(strip=True))\n",
    "            \n",
    "            if next_sibling.next_sibling.name in [\"h2\", \"h3\", \"h4\"]:\n",
    "                paragraphs.append(sibling_text)               \n",
    "            else:                \n",
    "                paragarph += sibling_text\n",
    "                \n",
    "            if next_sibling.next_sibling.name in ['pre', 'h2', 'h3', 'h4']:  # end\n",
    "                paragraphs.append(paragarph) \n",
    "                paragarph = \"\"\n",
    "            \n",
    "        if next_sibling.name in ['p']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)   \n",
    "            paragraphs.append(paragarph)            \n",
    "            paragarph = \"\"\n",
    "            paragraphs.append(sibling_text)            \n",
    "            \n",
    "        if next_sibling.name in ['div']:\n",
    "            \n",
    "            if paragarph:\n",
    "                paragraphs.append(paragarph)\n",
    "                # print(\"paragraphs:\", paragraphs)\n",
    "                paragarph = \"\"\n",
    "            \n",
    "            sibling_text = next_sibling.get_text(strip=False)\n",
    "            # print(\"sibling_text:\", sibling_text)\n",
    " \n",
    "  \n",
    "            # print(\"paragraphs:\", paragraphs)\n",
    "            \n",
    "  \n",
    "            paragraphs.append(sibling_text)\n",
    "            # print(\"paragraphs:\", paragraphs)\n",
    "              \n",
    "        # next_sibling = next_sibling.find_next_sibling()  # cannot find strings that are not enclosed in tags\n",
    "        next_sibling = next_sibling.next_sibling  # can find strings that are not enclosed in tags\n",
    "        # print(\"next_sibling:\", next_sibling.name, next_sibling.get_text(strip=True))\n",
    "        \n",
    "    tool_info['notes'] = paragraphs\n",
    "             \n",
    "    return tool_info\n",
    "\n",
    "def get_see_also_content(header, tool_info):\n",
    "    links = []\n",
    "    next_sibling = header.find_next_sibling()\n",
    "    # print(\"header:\", header, header.name)\n",
    "    # print(\"next_sibling:\", next_sibling.name, next_sibling,  next_sibling.get_text(strip=True))\n",
    "    # print(\"next_sibling:\", header.find_next_sibling())\n",
    "    \n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        if next_sibling.name in ['a', 'em']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)            \n",
    "            links =   sibling_text.split(\",\")   \n",
    "            \n",
    "                if next_sibling.name in ['a', 'em']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)            \n",
    "            links =   sibling_text.split(\",\")  \n",
    "            \n",
    "        next_sibling = next_sibling.find_next_sibling()  # cannot find strings that are not enclosed in tags\n",
    "        \n",
    "        # .next_sibling: This method only navigates the immediate next sibling node in the document. The sibling could be another tag, a text node, or even whitespace. If there is any text (including line breaks, spaces, etc.) between the <h2> and <em> tags, .next_sibling will return that text or whitespace instead of the <em> tag.\n",
    "             \n",
    "    tool_info['see_also'] = links\n",
    "             \n",
    "    return tool_info\n",
    "\n",
    "\n",
    "tool_info = {}\n",
    "for header in soup.find_all(['h2', 'h3', 'h4']):\n",
    "    header_text = header.get_text(strip=True)\n",
    "    \n",
    "    print(header_text)     \n",
    "    \n",
    "    if header_text == 'NAME':\n",
    "        get_name_content(header, tool_info)\n",
    "        \n",
    "    if header_text == 'KEYWORDS':\n",
    "        get_keywords_content(header, tool_info)\n",
    "        \n",
    "    if header_text == 'SYNOPSIS':\n",
    "        get_synopsis_content(header, tool_info)\n",
    "        \n",
    "    if header_text == 'Flags:':\n",
    "        get_flags_content(header, tool_info)\n",
    "        \n",
    "    if header_text == 'DESCRIPTION':\n",
    "        get_description_content(header, tool_info)\n",
    "        \n",
    "    if header_text == 'NOTES':\n",
    "        get_notes_content(header, tool_info)\n",
    "    \n",
    "    if header_text == 'SEE ALSO':\n",
    "        get_see_also_content(header, tool_info)\n",
    "        \n",
    "#     if header_text == 'AUTHOR':\n",
    "#         get_author_content(header, tool_info)      \n",
    "        \n",
    "#     if header_text == 'SOURCE CODE':\n",
    "#         get_source_code_content(header, tool_info)              \n",
    "        \n",
    "pprint.pprint(tool_info, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "136f440a-8146-4786-87cc-e283dace815b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.landsat.toar\n",
      "r.in.aster\n"
     ]
    }
   ],
   "source": [
    "for line in tool_info['see_also']:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "916c786f-17a2-4470-a383-9a2622ebccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internally, a gain code is defined to modify gains according to spectralbands following the GeoSystems GmbH ATCOR Ver. 2.0 Calibration Files.The function is defined in gain_aster.c file.\n",
      "/*Gain Code*/\n",
      "    /*0 - High (Not Applicable for band 10-14: TIR)*/\n",
      "    /*1 - Normal*/\n",
      "    /*2 - Low 1(Not Applicable for band 10-14: TIR)*/\n",
      "    /*3 - Low 2(Not Applicable for Band 1-3N/B and 10-14)*/\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in tool_info['notes']:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2be3414e-f405-4f30-9545-c056b98bbd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\\n<html>\\n<head>\\n <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\\n <meta name=\"Author\" content=\"GRASS Development Team\">\\n <meta http-equiv=\"content-language\" content=\"en-us\">\\n <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n <title>i.aster.toar - GRASS GIS manual</title>\\n <meta name=\"description\" content=\"i.aster.toar: Calculates Top of Atmosphere Radiance/Reflectance/Brightness Temperature from ASTER DN.\">\\n <meta name=\"keywords\" content=\"imagery, radiometric conversion, radiance, reflectance, brightness temperature, satellite, ASTER\">\\n <link rel=\"stylesheet\" href=\"grassdocs.css\" type=\"text/css\">\\n</head>\\n<body bgcolor=\"white\">\\n<div id=\"container\">\\n\\n<a href=\"index.html\"><img src=\"grass_logo.png\" alt=\"GRASS logo\"></a>\\n<script>\\n// Create hamburger menu TOC HTML elements by the JavaScript\\nlet temp = document.createElement(\\'template\\');\\nconst toc = \\'<ul class=\"toc-mobile-screen\" id=\"toc-mobile-screen\">\\' + \\n\\'<li><a class=\"toc-item\" href=\"#description\">DESCRIPTION</a>\\' + \\n\\'</li>\\' + \\n\\'<li><a class=\"toc-item\" href=\"#notes\">NOTES</a>\\' + \\n\\'</li>\\' + \\n\\'<li><a class=\"toc-item\" href=\"#see-also\">SEE ALSO</a>\\' + \\n\\'</li>\\' + \\n\\'<li><a class=\"toc-item\" href=\"#author\">AUTHOR</a>\\' + \\n\\'</li>\\' +\\n\\'<a class=\"close\" href=\"#\">\\' +\\n\\'<img src=\"./hamburger_menu_close.svg\" alt=\"close\">\\' +\\n\\'</a>\\' +\\n\\'</ul>\\' +\\n\\'<a class=\"hamburger\" href=\"#toc-mobile-screen\">\\' +\\n\\'<img src=\"./hamburger_menu.svg\" alt=\"menu\">\\' +\\n\\'</a>\\';\\ntemp.innerHTML = toc;\\nconst grassLogoLink = document.getElementsByTagName(\"img\")[0];\\ngrassLogoLink.after(temp.content);\\n</script>\\n<hr class=\"header\">\\n\\n<h2>NAME</h2>\\n<em><b>i.aster.toar</b></em>  - Calculates Top of Atmosphere Radiance/Reflectance/Brightness Temperature from ASTER DN.\\n<h2>KEYWORDS</h2>\\n<a href=\"imagery.html\">imagery</a>, <a href=\"topic_radiometric_conversion.html\">radiometric conversion</a>, <a href=\"keywords.html#radiance\">radiance</a>, <a href=\"keywords.html#reflectance\">reflectance</a>, <a href=\"keywords.html#brightness temperature\">brightness temperature</a>, <a href=\"keywords.html#satellite\">satellite</a>, <a href=\"keywords.html#ASTER\">ASTER</a>\\n<h2>SYNOPSIS</h2>\\n<div id=\"name\"><b>i.aster.toar</b><br></div>\\n<b>i.aster.toar --help</b><br>\\n<div id=\"synopsis\"><b>i.aster.toar</b> [-<b>rabcde</b>] <b>input</b>=<em>name</em>[,<i>name</i>,...] <b>dayofyear</b>=<em>float</em> <b>sun_elevation</b>=<em>float</em> <b>output</b>=<em>name</em>  [--<b>overwrite</b>]  [--<b>help</b>]  [--<b>verbose</b>]  [--<b>quiet</b>]  [--<b>ui</b>] \\n</div>\\n\\n<div id=\"flags\">\\n<h3>Flags:</h3>\\n<dl>\\n<dt><b>-r</b></dt>\\n<dd>Output is radiance (W/m2)</dd>\\n\\n<dt><b>-a</b></dt>\\n<dd>VNIR is High Gain</dd>\\n\\n<dt><b>-b</b></dt>\\n<dd>SWIR is High Gain</dd>\\n\\n<dt><b>-c</b></dt>\\n<dd>VNIR is Low Gain 1</dd>\\n\\n<dt><b>-d</b></dt>\\n<dd>SWIR is Low Gain 1</dd>\\n\\n<dt><b>-e</b></dt>\\n<dd>SWIR is Low Gain 2</dd>\\n\\n<dt><b>--overwrite</b></dt>\\n<dd>Allow output files to overwrite existing files</dd>\\n<dt><b>--help</b></dt>\\n<dd>Print usage summary</dd>\\n<dt><b>--verbose</b></dt>\\n<dd>Verbose module output</dd>\\n<dt><b>--quiet</b></dt>\\n<dd>Quiet module output</dd>\\n<dt><b>--ui</b></dt>\\n<dd>Force launching GUI dialog</dd>\\n</dl>\\n</div>\\n\\n<div id=\"parameters\">\\n<h3>Parameters:</h3>\\n<dl>\\n<dt><b>input</b>=<em>name[,<i>name</i>,...]</em>&nbsp;<b>[required]</b></dt>\\n<dd>Names of ASTER DN layers (15 layers)</dd>\\n\\n<dt><b>dayofyear</b>=<em>float</em>&nbsp;<b>[required]</b></dt>\\n<dd>Day of Year of satellite overpass [0-366]</dd>\\n\\n<dt><b>sun_elevation</b>=<em>float</em>&nbsp;<b>[required]</b></dt>\\n<dd>Sun elevation angle (degrees, &lt; 90.0)</dd>\\n\\n<dt><b>output</b>=<em>name</em>&nbsp;<b>[required]</b></dt>\\n<dd>Base name of the output layers (will add .x)</dd>\\n\\n</dl>\\n</div>\\n<div class=\"toc\">\\n<h4 class=\"toc\">Table of contents</h4>\\n<ul class=\"toc\">\\n    <li class=\"toc\"><a href=\"#description\" class=\"toc\">DESCRIPTION</a></li>\\n    <li class=\"toc\"><a href=\"#notes\" class=\"toc\">NOTES</a></li>\\n    <li class=\"toc\"><a href=\"#see-also\" class=\"toc\">SEE ALSO</a></li>\\n    <li class=\"toc\"><a href=\"#author\" class=\"toc\">AUTHOR</a></li>\\n</ul>\\n</div>\\n<h2><a name=\"description\">DESCRIPTION</a></h2>\\n\\n<em>i.aster.toar</em> calculates the Top Of Atmosphere (TOA) reflectance\\nfor Terra-ASTER L1B in the visible, NIR and SWIR bands (9+1 bands) and\\nbrightness temperature for the TIR bands (5 bands), all from L1B DN values.\\nIt is useful to apply after import of original ASTER imagery that\\nis generally in standard DN values range.\\n\\n<p>\\nThe order of input bands is\\n<ul>\\n<li> VNIR: 1,2,3N,3B\\n<li> SWIR: 4,5,6,7,8,9\\n<li> TIR: 10,11,12,13,14\\n</ul>\\nin one comma-separated list.\\n\\n<h2><a name=\"notes\">NOTES</a></h2>\\n\\nInternally, a gain code is defined to modify gains according to spectral\\nbands following the GeoSystems GmbH ATCOR Ver. 2.0 Calibration Files.\\nThe function is defined in gain_aster.c file.\\n\\n<div class=\"code\"><pre>\\n/*Gain Code*/\\n    /*0 - High (Not Applicable for band 10-14: TIR)*/\\n    /*1 - Normal*/\\n    /*2 - Low 1(Not Applicable for band 10-14: TIR)*/\\n    /*3 - Low 2(Not Applicable for Band 1-3N/B and 10-14)*/\\n</pre></div>\\n\\n<h2><a name=\"see-also\">SEE ALSO</a></h2>\\n\\n<em>\\n<a href=\"i.landsat.toar.html\">i.landsat.toar</a>,\\n<a href=\"r.in.aster.html\">r.in.aster</a>\\n</em>\\n\\n<p>\\nASTER sensor data download:\\n<a href=\"http://asterweb.jpl.nasa.gov/\">ASTER: Advanced Spaceborne Thermal Emission and Reflection Radiometer</a>\\n\\n<h2><a name=\"author\">AUTHOR</a></h2>\\n\\nYann Chemin, CSU, Australia\\n<h2>SOURCE CODE</h2>\\n<p>\\n  Available at:\\n  <a href=\"https://github.com/OSGeo/grass/tree/main/imagery/i.aster.toar\">i.aster.toar source code</a>\\n  (<a href=\"https://github.com/OSGeo/grass/commits/main/imagery/i.aster.toar\">history</a>)\\n</p>\\n<p>\\n  Latest change: Thursday Dec 22 12:39:17 2022 in commit: e0fe05696358cd50205279d4129f1d15934fae39\\n</p>\\n<hr class=\"header\">\\n<p>\\n<a href=\"index.html\">Main index</a> |\\n<a href=\"imagery.html\">Imagery index</a> |\\n<a href=\"topics.html\">Topics index</a> |\\n<a href=\"keywords.html\">Keywords index</a> |\\n<a href=\"graphical_index.html\">Graphical index</a> |\\n<a href=\"full_index.html\">Full index</a>\\n</p>\\n<p>\\n&copy; 2003-2024\\n<a href=\"https://grass.osgeo.org\">GRASS Development Team</a>,\\nGRASS GIS 8.4.1dev Reference Manual\\n</p>\\n\\n</div>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6105ec60-3cb0-4904-964d-b6bf6614dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i.aster.toar \\- GRASS GIS manual\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[![GRASS logo](grass_logo.png)](index.html)\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "NAME\n",
      "----\n",
      "\n",
      "\n",
      "***i.aster.toar*** \\- Calculates Top of Atmosphere Radiance/Reflectance/Brightness Temperature from ASTER DN.\n",
      "KEYWORDS\n",
      "--------\n",
      "\n",
      "\n",
      "[imagery](imagery.html), [radiometric conversion](topic_radiometric_conversion.html), [radiance](keywords.html#radiance), [reflectance](keywords.html#reflectance), [brightness temperature](keywords.html#brightness temperature), [satellite](keywords.html#satellite), [ASTER](keywords.html#ASTER)\n",
      "SYNOPSIS\n",
      "--------\n",
      "\n",
      "\n",
      "**i.aster.toar**  \n",
      "\n",
      "**i.aster.toar \\-\\-help**  \n",
      "\n",
      "**i.aster.toar** \\[\\-**rabcde**] **input**\\=*name*\\[,*name*,...] **dayofyear**\\=*float* **sun\\_elevation**\\=*float* **output**\\=*name* \\[\\-\\-**overwrite**] \\[\\-\\-**help**] \\[\\-\\-**verbose**] \\[\\-\\-**quiet**] \\[\\-\\-**ui**] \n",
      "\n",
      "\n",
      "### Flags:\n",
      "\n",
      "\n",
      "\n",
      "**\\-r**\n",
      "Output is radiance (W/m2\\)\n",
      "**\\-a**\n",
      "VNIR is High Gain\n",
      "**\\-b**\n",
      "SWIR is High Gain\n",
      "**\\-c**\n",
      "VNIR is Low Gain 1\n",
      "**\\-d**\n",
      "SWIR is Low Gain 1\n",
      "**\\-e**\n",
      "SWIR is Low Gain 2\n",
      "**\\-\\-overwrite**\n",
      "Allow output files to overwrite existing files\n",
      "**\\-\\-help**\n",
      "Print usage summary\n",
      "**\\-\\-verbose**\n",
      "Verbose module output\n",
      "**\\-\\-quiet**\n",
      "Quiet module output\n",
      "**\\-\\-ui**\n",
      "Force launching GUI dialog\n",
      "\n",
      "\n",
      "\n",
      "### Parameters:\n",
      "\n",
      "\n",
      "\n",
      "**input**\\=*name\\[,*name*,...]*Â **\\[required]**\n",
      "Names of ASTER DN layers (15 layers)\n",
      "**dayofyear**\\=*float*Â **\\[required]**\n",
      "Day of Year of satellite overpass \\[0\\-366]\n",
      "**sun\\_elevation**\\=*float*Â **\\[required]**\n",
      "Sun elevation angle (degrees, \\< 90\\.0\\)\n",
      "**output**\\=*name*Â **\\[required]**\n",
      "Base name of the output layers (will add .x)\n",
      "\n",
      "\n",
      "\n",
      "#### Table of contents\n",
      "\n",
      "\n",
      "* [DESCRIPTION](#description)\n",
      "* [NOTES](#notes)\n",
      "* [SEE ALSO](#see-also)\n",
      "* [AUTHOR](#author)\n",
      "\n",
      "\n",
      "\n",
      "DESCRIPTION\n",
      "-----------\n",
      "\n",
      "\n",
      "*i.aster.toar* calculates the Top Of Atmosphere (TOA) reflectance\n",
      "for Terra\\-ASTER L1B in the visible, NIR and SWIR bands (9\\+1 bands) and\n",
      "brightness temperature for the TIR bands (5 bands), all from L1B DN values.\n",
      "It is useful to apply after import of original ASTER imagery that\n",
      "is generally in standard DN values range.\n",
      "\n",
      "\n",
      "The order of input bands is\n",
      "* VNIR: 1,2,3N,3B\n",
      "* SWIR: 4,5,6,7,8,9\n",
      "* TIR: 10,11,12,13,14\n",
      "\n",
      "\n",
      "in one comma\\-separated list.\n",
      "\n",
      "NOTES\n",
      "-----\n",
      "\n",
      "\n",
      "\n",
      "Internally, a gain code is defined to modify gains according to spectral\n",
      "bands following the GeoSystems GmbH ATCOR Ver. 2\\.0 Calibration Files.\n",
      "The function is defined in gain\\_aster.c file.\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "/*Gain Code*/\n",
      "    /*0 - High (Not Applicable for band 10-14: TIR)*/\n",
      "    /*1 - Normal*/\n",
      "    /*2 - Low 1(Not Applicable for band 10-14: TIR)*/\n",
      "    /*3 - Low 2(Not Applicable for Band 1-3N/B and 10-14)*/\n",
      "\n",
      "```\n",
      "\n",
      "SEE ALSO\n",
      "--------\n",
      "\n",
      "\n",
      "*[i.landsat.toar](i.landsat.toar.html),\n",
      "[r.in.aster](r.in.aster.html)*\n",
      "\n",
      "ASTER sensor data download:\n",
      "[ASTER: Advanced Spaceborne Thermal Emission and Reflection Radiometer](http://asterweb.jpl.nasa.gov/)\n",
      "AUTHOR\n",
      "------\n",
      "\n",
      "\n",
      "\n",
      "Yann Chemin, CSU, Australia\n",
      "SOURCE CODE\n",
      "-----------\n",
      "\n",
      "\n",
      "\n",
      " Available at:\n",
      " [i.aster.toar source code](https://github.com/OSGeo/grass/tree/main/imagery/i.aster.toar)\n",
      " ([history](https://github.com/OSGeo/grass/commits/main/imagery/i.aster.toar))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Latest change: Thursday Dec 22 12:39:17 2022 in commit: e0fe05696358cd50205279d4129f1d15934fae39\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "[Main index](index.html) \\|\n",
      "[Imagery index](imagery.html) \\|\n",
      "[Topics index](topics.html) \\|\n",
      "[Keywords index](keywords.html) \\|\n",
      "[Graphical index](graphical_index.html) \\|\n",
      "[Full index](full_index.html)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Â© 2003\\-2024\n",
      "[GRASS Development Team](https://grass.osgeo.org),\n",
      "GRASS GIS 8\\.4\\.1dev Reference Manual\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! pip install html2text\n",
    "# ! pip install markdownify\n",
    "\n",
    "import html2text\n",
    "from markdownify import markdownify\n",
    "\n",
    "\n",
    "html_content = \"\"\"\n",
    "<h1>Title</h1>\n",
    "<p>This is a <strong>bold</strong> paragraph.</p>\n",
    "<a href=\"https://example.com\">Link to Example</a>\n",
    "\"\"\"\n",
    "\n",
    "# Convert HTML to Markdown\n",
    "# markdown_content = html2text.html2text( requests.get(url).content)\n",
    "markdown_content = markdownify( requests.get(url).content)\n",
    "\n",
    "# Print the result\n",
    "print(markdown_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d4cfdbea-f190-474b-9e1a-916209c0702f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'i.aster.toar',\n",
       " 'brief_description': 'Calculates Top of Atmosphere Radiance/Reflectance/Brightness Temperature from ASTER DN.',\n",
       " 'keywords': ['imagery',\n",
       "  'radiometric conversion',\n",
       "  'radiance',\n",
       "  'reflectance',\n",
       "  'brightness temperature',\n",
       "  'satellite',\n",
       "  'ASTER'],\n",
       " 'synopsis': ['i.aster.toar',\n",
       "  'i.aster.toar --help',\n",
       "  'i.aster.toar[-rabcde]input=name[,name,...]dayofyear=floatsun_elevation=floatoutput=name[--overwrite]  [--help]  [--verbose]  [--quiet]  [--ui]'],\n",
       " 'Flags': {'-r': 'Output is radiance (W/m2)',\n",
       "  '-a': 'VNIR is High Gain',\n",
       "  '-b': 'SWIR is High Gain',\n",
       "  '-c': 'VNIR is Low Gain 1',\n",
       "  '-d': 'SWIR is Low Gain 1',\n",
       "  '-e': 'SWIR is Low Gain 2',\n",
       "  '--overwrite': 'Allow output files to overwrite existing files',\n",
       "  '--help': 'Print usage summary',\n",
       "  '--verbose': 'Verbose module output',\n",
       "  '--quiet': 'Quiet module output',\n",
       "  '--ui': 'Force launching GUI dialog'},\n",
       " 'description': ['i.aster.toar calculates the Top Of Atmosphere (TOA) reflectancefor Terra-ASTER L1B in the visible, NIR and SWIR bands (9+1 bands) andbrightness temperature for the TIR bands (5 bands), all from L1B DN values.It is useful to apply after import of original ASTER imagery thatis generally in standard DN values range.',\n",
       "  'The order of input bands is',\n",
       "  'â€¢ VNIR: 1,2,3N,3B',\n",
       "  'â€¢ SWIR: 4,5,6,7,8,9',\n",
       "  'â€¢ TIR: 10,11,12,13,14',\n",
       "  'in one comma-separated list.'],\n",
       " 'notes': ['Internally, a gain code is defined to modify gains according to spectralbands following the GeoSystems GmbH ATCOR Ver. 2.0 Calibration Files.The function is defined in gain_aster.c file.',\n",
       "  '/*Gain Code*/\\n    /*0 - High (Not Applicable for band 10-14: TIR)*/\\n    /*1 - Normal*/\\n    /*2 - Low 1(Not Applicable for band 10-14: TIR)*/\\n    /*3 - Low 2(Not Applicable for Band 1-3N/B and 10-14)*/\\n',\n",
       "  '',\n",
       "  '']}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "34f9a00c-be6d-49dd-9daf-b4882d83500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.aster.toar calculates the Top Of Atmosphere (TOA) reflectancefor Terra-ASTER L1B in the visible, NIR and SWIR bands (9+1 bands) andbrightness temperature for the TIR bands (5 bands), all from L1B DN values.It is useful to apply after import of original ASTER imagery thatis generally in standard DN values range.\n",
      "The order of input bands is\n",
      "â€¢ VNIR: 1,2,3N,3B\n",
      "â€¢ SWIR: 4,5,6,7,8,9\n",
      "â€¢ TIR: 10,11,12,13,14\n",
      "in one comma-separated list.\n"
     ]
    }
   ],
   "source": [
    "# pprint.pprint(tool_info, width=800)\n",
    "for line in tool_info['description']:\n",
    "    print(line)\n",
    "\n",
    "# len(soup.find_all(\"p\"))\n",
    "# soup.find_all(\"p\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eeb7e-82d7-40fd-be6f-13b45085bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Extract_GRASS_doc:\n",
    "    def __init__(self, soup):\n",
    "        self.soup = soup        \n",
    "        \n",
    "    def NAME(self):\n",
    "        return\n",
    "    \n",
    "    def KEYWORDS(self):\n",
    "        return\n",
    "    \n",
    "    def SYNOPSIS(self):\n",
    "        return\n",
    "    \n",
    "    def Flags(self):\n",
    "        return\n",
    "    \n",
    "    def Parameters(self):\n",
    "        return\n",
    "    \n",
    "    def DESCRIPTION(self):\n",
    "        return\n",
    "    \n",
    "    def SEE_ALSO(self):\n",
    "        return\n",
    " \n",
    "    def NOTES(self):\n",
    "        return    \n",
    "    \n",
    "    def AUTHOR(self):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def SOURCE_CODE(self):\n",
    "        return    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # grass_html.NAME()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363192b-3eea-4c00-a3d1-854fa2639fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "soup = get_response(url)\n",
    "\n",
    "# Dictionary to hold headers and their associated content\n",
    " \n",
    "content_dict = {}\n",
    "\n",
    "# Function to get content associated with each header\n",
    "def get_associated_content(header):\n",
    "    content = []\n",
    "    next_sibling = header.find_next_sibling()\n",
    "    \n",
    "    while next_sibling and next_sibling.name not in ['h2', 'h3', 'h4']:\n",
    "        # Handle elements with tags\n",
    "        if next_sibling.name in ['a', 'p', 'em', 'div',  'b', 'dd', 'dt', 'dl', 'pre']:\n",
    "            sibling_text = next_sibling.get_text(strip=True)\n",
    "            print(\"sibling_text:\", sibling_text)\n",
    "            content.append(sibling_text)\n",
    "        # Handle inline text outside of tags\n",
    "        if next_sibling.next_sibling and isinstance(next_sibling.next_sibling, str):\n",
    "            sibling_text = next_sibling.next_sibling.strip()\n",
    "            print(\"sibling_text:\", sibling_text)\n",
    "            content.append(sibling_text)\n",
    "            \n",
    "        next_sibling = next_sibling.find_next_sibling()\n",
    "    \n",
    "    return ' '.join(content)\n",
    "\n",
    "# Variables to track current headers\n",
    "current_h2 = None\n",
    "current_h3 = None\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over all headers (h2, h3, h4) and extract their content\n",
    "for header in soup.find_all(['h2', 'h3', 'h4']):\n",
    "    header_text = header.get_text(strip=True)\n",
    "    content = get_associated_content(header)\n",
    "    \n",
    "    if header.name == 'h2':\n",
    "        # New h2 header, reset the hierarchy\n",
    "        content_dict[header_text] = {\"content\": content}\n",
    "        current_h2 = header_text\n",
    "        current_h3 = None\n",
    "    \n",
    "    elif header.name == 'h3' and current_h2:\n",
    "        # h3 is nested directly under the current h2\n",
    "        content_dict[current_h2][header_text] = {\"content\": content}\n",
    "        current_h3 = header_text\n",
    "    \n",
    "    elif header.name == 'h4' and current_h2 and current_h3:\n",
    "        # h4 is nested directly under the current h3\n",
    "        content_dict[current_h2][header_text] = content\n",
    "\n",
    "# Save the result to a JSON file\n",
    "with open('headers_and_content.json', 'w') as json_file:\n",
    "    json.dump(content_dict, json_file, indent=4)\n",
    "\n",
    "print(\"Headers and content extracted and saved to headers_and_content.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b30a13-2dda-4174-b89c-ae3dada8aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "pp.pprint(content_dict )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_geo",
   "language": "python",
   "name": "llm_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
