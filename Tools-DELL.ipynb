{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4baa4d-118a-48a3-b637-de16f84c6dc0",
   "metadata": {},
   "source": [
    "# Test data_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7405086b-b272-436c-9345-9013e9ab640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyvisa\n",
    "# ! pip install toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97a09f-d496-49f0-8565-ddf45eb932f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318bd40-d468-4002-a308-01d624b699cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464945e2-5830-4a1e-bd2e-bc3dc96c5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os    \n",
    "import sys    \n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"Modules\"))    \n",
    "import Modules.data_eye as data_eye\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "590af424-5feb-44d5-8129-fa29a5183590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names, data types, and sample values (column_name: data_type, sample value |):[FIPS: object, US37001020100 | CountyFIPS: int64, 37001 | StateAbbreviation: object, NC | AreaTotal: float64, 1.741972 | TotalPopulation: int64, 4058 | White: int64, 2474 | BlackAfricanAmerican: int64, 1157 | AmericanIndianAlaskaNative: int64, 13 | Asian : int64, 72 | NativeHawaiianOtherPacificIslander: int64, 0 | SomeOtherRace: int64, 265 | TwoOrMoreRaces: int64, 77 | GEOID: int64, 37001020100 ]\n"
     ]
    }
   ],
   "source": [
    "file_path = r'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv'\n",
    "meta_str = data_eye.see_table(file_path)\n",
    "# meta_str = data_eye.see_vector(file_path)\n",
    "\n",
    "print(meta_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c83f407b-2130-4a2c-9add-0dfcd91f04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'column names and data types': 'column names, data types, and sample values (column_name: data_type, sample value |):[fd_id: int64, 538984000| bid: object, 869CW7WM+PWH-3-4-3-5| cbfips: object, 291618910003018| st_damcat: object, RES| occtype: object, RES1-2SWB| bldgtype: object, W| num_story: float64, 2.0| sqft: float64, 3058.0| found_type: object, B| found_ht: float64, 2.0| med_yr_blt: int64, 1988| val_struct: float64, 309288.845| val_cont: float64, 154644.422| val_vehic: float64, 27000.0| ftprntid: object, 29161_9163| ftprntsrc: object, Bing| source: object, P| students: int64, 0| pop2amu65: int64, 2| pop2amo65: int64, 1| pop2pmu65: int64, 1| pop2pmo65: int64, 1| o65disable: float64, 0.23| u65disable: float64, 0.06| x: float64, -91.71515119| y: float64, 37.94681358| firmzone: object, None| grnd_elv_m: float64, 289.49740601| ground_elv: float64, 949.79466952]', 'Coordinate reference system': 'EPSG:4326'}\n"
     ]
    }
   ],
   "source": [
    "file_path = r'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip'\n",
    "file_path = r\"D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\TGI\\Phelps\\Rolla_NSI8k.shp\"\n",
    "meta_str = data_eye.see_vector(file_path)\n",
    "print(meta_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21be1b05-604f-403a-9197-f2df5eca74ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'int16', 'nodata': None, 'width': 1440, 'height': 1260, 'crs': CRS.from_epsg(4326), 'transform': Affine(0.0002777777777778173, 0.0, 86.73000000003759,\n",
      "       0.0, -0.0002777777777778173, 28.169999999992058), 'band_count': 1, 'bounds': BoundingBox(left=86.73000000003759, bottom=27.819999999992007, right=87.13000000003765, top=28.169999999992058), 'resolution': (0.0002777777777778173, -0.0002777777777778173), 'unit': 'degree'}\n"
     ]
    }
   ],
   "source": [
    "file_path = r'https://github.com/gladcolor/spatial_data/raw/refs/heads/master/Everest_DEM.tif'\n",
    "meta_str = data_eye.see_raster(file_path)\n",
    "print(meta_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ac594da-b54c-42b0-86b1-e749b7369b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'JP2OpenJPEG', 'dtype': 'uint16', 'nodata': None, 'width': 1830, 'height': 1830, 'crs': CRS.from_epsg(32631), 'transform': Affine(60.0, 0.0, 199980.0,\n",
      "       0.0, -60.0, 4600020.0), 'band_count': 1, 'bounds': BoundingBox(left=199980.0, bottom=4490220.0, right=309780.0, top=4600020.0), 'statistics': {'band_1': [Statistics(min=968.0, max=3041.0, mean=1728.9038839619, std=223.7525359002)]}, 'resolution': (60.0, -60.0), 'unit': 'metre'}\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "\n",
    "file_path = r'https://github.com/gladcolor/spatial_data/raw/refs/heads/master/Everest_DEM.tif'\n",
    "file_path = r'https://github.com/gladcolor/spatial_data/raw/refs/heads/master/Everest_DOM.tif'\n",
    "file_path = r\"D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\QGIS_plugin\\sentinel2.tif\"\n",
    "file_path = r\"C:\\Users\\A\\Downloads\\Sentinel_downloaded\\L1C_T31TBF_A043377_20231012T105229_2023-10-12\\L1C_T31TBF_A043377_20231012T105229_B09.jp2\"\n",
    "print(data_eye.see_raster(file_path, statistics=True))\n",
    "\n",
    "# dataset = rasterio.open(file_path)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "021eecb6-34e3-46bf-8306-89a24dd04f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'JP2OpenJPEG',\n",
       " 'dtype': 'uint16',\n",
       " 'nodata': None,\n",
       " 'width': 1830,\n",
       " 'height': 1830,\n",
       " 'count': 1,\n",
       " 'crs': CRS.from_epsg(32631),\n",
       " 'transform': Affine(60.0, 0.0, 199980.0,\n",
       "        0.0, -60.0, 4600020.0)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29e5483e-258e-4cf1-948f-5208813ce117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.crs: None\n",
      "{'driver': 'JPEG', 'dtype': 'uint8', 'nodata': None, 'width': 1228, 'height': 1228, 'crs': None, 'transform': Affine(1.0, 0.0, 0.0,\n",
      "       0.0, 1.0, 0.0), 'band_count': 3, 'bounds': BoundingBox(left=0.0, bottom=1228.0, right=1228.0, top=0.0), 'statistics': {'band_1': Statistics(min=6.0, max=160.0, mean=60.181304310921, std=22.755696605463), 'band_2': Statistics(min=34.0, max=130.0, mean=77.360426237944, std=10.928412040113), 'band_3': Statistics(min=50.0, max=108.0, mean=72.09645526743, std=6.6811376621009)}, 'resolution': (1.0, 1.0), 'Coordinate reference system': 'unknow'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\Python_code\\Modules\\data_eye.py:134: RasterioDeprecationWarning: statistics() will be removed in 2.0.0. Please switch to stats().\n",
      "  band_stat_dict[f\"band_{i}\"] = dataset.statistics(i, approx=approx)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a79f2be-0b4f-4c57-b3c5-94a64b43bcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your mission: You will be provided with brief geospatial data description and locations for a spatial analysis task.\n",
      "You need to extract the data path, URL, API, an format from a task and data description. Every given data should be included, and keep the original order.\n",
      "Below are the description of your reply parameters:\n",
      "- location: the disk path, URL, or API to access the data. Such as r\"C:\\test.zip\".\n",
      "- format: the format of data, which belongs one of ['TXT', 'CSV', 'Parquet', 'ESRI shapefile', 'KML', 'HDF', 'HDF5', 'LAS/LAZ', 'XLS', 'GML', 'GeoPackage', 'Tiff', 'JPEG', 'PNG', 'URL', 'REST API', 'other']\n",
      " \n",
      "\n",
      "Given task description: 1) Find out Census tracts that contain hazardous waste facilities, then comppute and print out the population living in those tracts. The study area is North Carolina (NC), US.\n",
      "2) Generate a population choropleth map for all tract polygons in NC, rendering the color by tract population; and then highlight the borders of tracts that have hazardous waste facilities. Please draw all polygons, not only the highlighted ones. The map size is 15*10 inches.\n",
      " \n",
      "Data location: \n",
      "1. NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip.\n",
      "2. NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip.\n",
      "3. NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "file_path = r'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv'\n",
    "# meta_str = data_eye.see_table(file_path)\n",
    "# print(meta_str)\n",
    "\n",
    "task_name ='Resident_at_risk_counting'\n",
    "TASK = r\"\"\"1) Find out Census tracts that contain hazardous waste facilities, then comppute and print out the population living in those tracts. The study area is North Carolina (NC), US.\n",
    "2) Generate a population choropleth map for all tract polygons in NC, rendering the color by tract population; and then highlight the borders of tracts that have hazardous waste facilities. Please draw all polygons, not only the highlighted ones. The map size is 15*10 inches.\n",
    "\"\"\"\n",
    "\n",
    "DATA_LOCATIONS = [\"NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip.\",\n",
    "                  \"NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip.\",\n",
    "                  \"NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. \"\n",
    "                 ]\n",
    "prompt = data_eye.get_prompt_to_pick_up_data_locations(task=TASK,\n",
    "                                                       data_locations=DATA_LOCATIONS)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32808c64-b141-4c48-a34c-232ffcc296eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip.NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip. Data overview: {'column names and data types': '[FID: int32, HANDLER_ID: object, SITE_NAME: object, LOC_STR_NO: object, LOC_ADDR_1: object, LOC_ADDR_2: object, LOC_CITY: object, LOC_COUNTY: object, LOC_ZIP: object, CONTACT_NA: object, CONTACT_PH: object, GENERATOR: object, TRANSPORTE: object, TREATER: object, STORER: object, LAND_UNIT: object, HSWA_PERMI: object, LAT: float64, LONG: float64, HCS_CODE: int32, HCS_REF: object, HCS_RES: object]', 'Coordinate reference system': 'EPSG:4326'}\", \"NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip.NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip. Data overview: {'column names and data types': '[Tract: object, SUM_ALAND: float64, SUM_AWATER: float64, state_code: object, GEOID: int64]', 'Coordinate reference system': 'EPSG:4326'}\", 'NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv.  Data overview: [FIPS: object, CountyFIPS: int64, StateAbbreviation: object, AreaTotal: float64, TotalPopulation: int64, White: int64, BlackAfricanAmerican: int64, AmericanIndianAlaskaNative: int64, Asian : int64, NativeHawaiianOtherPacificIslander: int64, SomeOtherRace: int64, TwoOrMoreRaces: int64, GEOID: int64]']\n"
     ]
    }
   ],
   "source": [
    "attributes_json, data_location_list = data_eye.add_data_overview_to_data_location(task=TASK, data_location_list=DATA_LOCATIONS, model=r'gpt-4o-2024-08-06')\n",
    "print(data_location_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c054bb-7ce8-468d-a512-fa556265de8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip.NC hazardous waste facility ESRI shape file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip. Data overview: {'column names and data types': '[FID: int32, HANDLER_ID: object, SITE_NAME: object, LOC_STR_NO: object, LOC_ADDR_1: object, LOC_ADDR_2: object, LOC_CITY: object, LOC_COUNTY: object, LOC_ZIP: object, CONTACT_NA: object, CONTACT_PH: object, GENERATOR: object, TRANSPORTE: object, TREATER: object, STORER: object, LAND_UNIT: object, HSWA_PERMI: object, LAT: float64, LONG: float64, HCS_CODE: int32, HCS_REF: object, HCS_RES: object]', 'Coordinate reference system': 'EPSG:4326'}\",\n",
       " \"NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip.NC tract boundary shapefile: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip. Data overview: {'column names and data types': '[Tract: object, SUM_ALAND: float64, SUM_AWATER: float64, state_code: object, GEOID: int64]', 'Coordinate reference system': 'EPSG:4326'}\",\n",
       " 'NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv. NC tract population CSV file: https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv.  Data overview: [FIPS: object, CountyFIPS: int64, StateAbbreviation: object, AreaTotal: float64, TotalPopulation: int64, White: int64, BlackAfricanAmerican: int64, AmericanIndianAlaskaNative: int64, Asian : int64, NativeHawaiianOtherPacificIslander: int64, SomeOtherRace: int64, TwoOrMoreRaces: int64, GEOID: int64]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_LOCATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58117d75-9ca0-4409-b086-25064eee04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "import time\n",
    "import data_eye_constants as eye_constants\n",
    "\n",
    "\n",
    "model = r'gpt-4o-2024-08-06'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0440d7-bc12-420d-b836-fd358e507fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_locations': [{'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip',\n",
       "   'format': 'ESRI shapefile'},\n",
       "  {'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip',\n",
       "   'format': 'ESRI shapefile'},\n",
       "  {'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv',\n",
       "   'format': 'CSV'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "result = data_eye.get_LLM_reply(prompt=prompt, model=model)\n",
    "# pprint.pp(result.choices[0].message)\n",
    "attributes_json = json.loads(result.choices[0].message.content)\n",
    "attributes_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a272858c-2b2d-4a4d-a823-5ea59aaaae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_locations': [{'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip',\n",
       "   'format': 'ESRI shapefile'},\n",
       "  {'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip',\n",
       "   'format': 'ESRI shapefile'},\n",
       "  {'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv',\n",
       "   'format': 'CSV'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e8578d-0191-40db-9e1a-c11751ffbe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_locations': [{'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/HW_Sites_EPSG4326.zip',\n",
       "   'format': 'ESRI shapefile',\n",
       "   'meta_str': \"{'column names and data types': '[FID: int32, HANDLER_ID: object, SITE_NAME: object, LOC_STR_NO: object, LOC_ADDR_1: object, LOC_ADDR_2: object, LOC_CITY: object, LOC_COUNTY: object, LOC_ZIP: object, CONTACT_NA: object, CONTACT_PH: object, GENERATOR: object, TRANSPORTE: object, TREATER: object, STORER: object, LAND_UNIT: object, HSWA_PERMI: object, LAT: float64, LONG: float64, HCS_CODE: int32, HCS_REF: object, HCS_RES: object]', 'Coordinate reference system': 'EPSG:4326'}\"},\n",
       "  {'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/tract_37_EPSG4326.zip',\n",
       "   'format': 'ESRI shapefile',\n",
       "   'meta_str': \"{'column names and data types': '[Tract: object, SUM_ALAND: float64, SUM_AWATER: float64, state_code: object, GEOID: int64]', 'Coordinate reference system': 'EPSG:4326'}\"},\n",
       "  {'location': 'https://github.com/gladcolor/LLM-Geo/raw/master/overlay_analysis/NC_tract_population.csv',\n",
       "   'format': 'CSV',\n",
       "   'meta_str': '[FIPS: object, CountyFIPS: int64, StateAbbreviation: object, AreaTotal: float64, TotalPopulation: int64, White: int64, BlackAfricanAmerican: int64, AmericanIndianAlaskaNative: int64, Asian : int64, NativeHawaiianOtherPacificIslander: int64, SomeOtherRace: int64, TwoOrMoreRaces: int64, GEOID: int64]'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eye.get_data_overview(attributes_json)\n",
    "attributes_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73bac561-4e70-4bce-82be-872f5c551bb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace expected at least 2 arguments, got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mattributes_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_locations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeta_str\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: replace expected at least 2 arguments, got 0"
     ]
    }
   ],
   "source": [
    "attributes_json['data_locations'][0]['meta_str'].replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e5f74-beb5-4adf-ad91-58fb3bfe41f1",
   "metadata": {},
   "source": [
    "# QGIS help page crawler\n",
    "\n",
    "https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db433b-e90c-4ef3-aa9f-1a321e53e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "packages = ['openai', 'qswitchcontrol', 'nest-asyncio', 'pyqtwebengine_qt5','pyqtwebengine', 'networkx','pyvis','geopandas','IPython','iface','regex']  #Replace 'numpy' with the name of the package you want to uninstall\n",
    "for package in packages:\n",
    "    pip.main(['uninstall', package, '-y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56544e2d-ec00-4fa1-95b6-a49074f91dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729fc5cf-fee8-4976-932c-9bdc1955ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.1.15. Raster analysis — QGIS Documentation  documentation\n"
     ]
    }
   ],
   "source": [
    "url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    html_content = response.content\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Now you can work with 'soup' to extract the relevant sections\n",
    "    # Example: printing the title of the page\n",
    "    print(soup.title.get_text())\n",
    " \n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "065e8e84-a57b-4fc4-9803-51eb3fed2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, section in enumerate(sections):\n",
    "    # print(idx)\n",
    "    # print(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8cc07ac1-e636-4f1e-bdaf-452f54bb6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for idx, section in enumerate(sections):\n",
    "#     cnt\n",
    "#     section_id = section.get('id')  # Extract the section ID\n",
    "#     h3_tag = section.find('h2')  # Try to find an <h3> tag in the section\n",
    "#     if h3_tag:\n",
    "#         cnt += 1\n",
    "#         print(idx, cnt, f\"Section with ID '{section_id}' contains an <h3> tag: '{h3_tag.get_text()}'\")\n",
    "#         # cnt += 1\n",
    "#     else:\n",
    "#         # print(idx, f\"Section with ID '{section_id}' does not contain an <h3> tag.\")\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "84abdfe5-b191-4f7d-aa31-8c3f483e2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup\n",
    "import toml\n",
    "import os\n",
    "import re\n",
    "\n",
    "sections = soup.find_all('section')[2:]  # Using find_all to get all sections\n",
    "count = 0\n",
    "\n",
    "\n",
    "def extract_table(section):\n",
    "    table_data = []\n",
    "    table = section.find('table')\n",
    "    if table:\n",
    "        headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "        rows = table.find_all('tr')[1:]  # Skip header row\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            # row_data = {headers[i]: cols[i].get_text(strip=True) for i in range(len(headers))}\n",
    "            row_data = {headers[i]: cols[i].get_text(separator=' ', strip=True) for i in range(len(headers))}\n",
    "            table_data.append(row_data)\n",
    "    return table_data\n",
    "    \n",
    "# Helper function to normalize whitespace in a string\n",
    "def normalize_whitespace(text):\n",
    "    # Replace multiple spaces and newlines with a single space\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "# Function to extract paragraphs before a section with a specific id and ensure spaces around <a> and <code> elements\n",
    "def extract_paragraphs_before(section, stop_section_id):\n",
    "    paragraphs = []\n",
    "    \n",
    "    for element in section.find_all(['p', 'h3'], recursive=False):\n",
    "        # Stop if we encounter the sub-section (like \"Parameters\")\n",
    "        if element.name == 'h3' and stop_section_id in element.get('id', ''):\n",
    "            break\n",
    "        if element.name == 'p':\n",
    "            # Rebuild the paragraph's text, ensuring spaces around <a> and <code> tags\n",
    "            paragraph_text = []\n",
    "            for content in element.children:\n",
    "                \n",
    "                if content.name in ['a', 'code']:\n",
    "                    paragraph_text.append(f\" {content.get_text(strip=True)} \")\n",
    "                    # print(content)\n",
    "                else:\n",
    "                    paragraph_text.append(content if isinstance(content, str) else content.get_text(strip=True))\n",
    "                    # print(paragraph_text[-1])\n",
    "            \n",
    "            paragraphs.append(normalize_whitespace(''.join(paragraph_text)))\n",
    "    \n",
    "    return paragraphs\n",
    "    \n",
    "def make_parameters_for_TOML(tool_info):\n",
    "    lines = []\n",
    "    for parameter in tool_info['basic_parameters']:\n",
    "        line = f\"{parameter['Name']}: {parameter['Description'].replace('\\n', '')}. Type: {parameter['Type']}\"\n",
    "        lines.append(line)\n",
    "        \n",
    "    for parameter in tool_info['advanced_parameters']:\n",
    "        line = f\"{parameter['Name']}: {parameter['Description'].replace('\\n', '')}. Type: {parameter['Type']}\"\n",
    "        lines.append(line)\n",
    "    \n",
    "    para_str = \"\\n\".join(lines)\n",
    "    return para_str\n",
    "\n",
    "def make_TOML_file(tool_info, fname):\n",
    "    tool_toml = {}\n",
    "    tool_toml['tool_ID'] = tool_info['algorithm_id']\n",
    "    tool_toml['tool_name'] = tool_info['tool_name']    \n",
    "    tool_toml['brief_description'] = tool_info['brief_description']\n",
    "    tool_toml['full_description'] = '\\n'.join(tool_info['paragraphs'])\n",
    "    tool_toml['parameters'] = make_parameters_for_TOML(tool_info)\n",
    "    tool_toml['code_example'] = \"\"\n",
    "    with open(fname, 'w') as f:\n",
    "        toml_str = toml.dump(tool_toml, f)\n",
    "        \n",
    "    # toml_str = toml.dumps(tool_toml)\n",
    "    return toml_str\n",
    "    \n",
    "def extract_tool_info(section):\n",
    "\n",
    "    tool_info = {}\n",
    "    section_id = section.get('id')\n",
    "    # print(\"section_id:\", section_id)\n",
    "    \n",
    "    h2 = section.find(\"h2\")\n",
    "    \n",
    "    if h2:  # Check if an h2 element was found\n",
    "        # Extract the text, remove the trailing character, split by \".\", and get the last part\n",
    "        # tool_info = {}\n",
    "        print(\"Tool:\", h2.get_text(strip=True)[:-1])   # .split(\".\")[-1][:-1]\n",
    "        paragraph = section.find(\"p\")\n",
    "        if paragraph:\n",
    "            # print(\"Tool description:\", paragraph.get_text(strip=True))\n",
    "             #<><span class=\"pre\">native:cellstackpercentrankfromvalue</span></code>\n",
    "            paragraphs = extract_paragraphs_before(section, 'parameters')\n",
    " \n",
    "            if len(paragraphs) > 0:\n",
    "                tool_info['brief_description'] = paragraphs[0]\n",
    "                # print(\"Tool description:\", tool_info['brief_description'])  \n",
    "            else: \n",
    "                tool_info['brief_description'] = \"\"\n",
    "            tool_info['tool_name'] = h2.get_text(strip=True)[:-1].split(\".\")[-1] \n",
    "            tool_info['paragraphs'] = paragraphs\n",
    " \n",
    "        # Extract the Algorithm ID\n",
    "        algorithm_id = None\n",
    "        python_code_snippet = None\n",
    "        python_code_section = section.find('section', id='python-code')\n",
    "        print(\"python_code_section:\", python_code_section)\n",
    "        if python_code_section:\n",
    "            algorithm_id = python_code_section.find('code').get_text(strip=True)\n",
    "            # Extract the Python code snippet inside the <pre> tag\n",
    "            pre_tag = python_code_section.find('pre')\n",
    "            if pre_tag:\n",
    "                python_code_snippet = pre_tag.get_text()\n",
    "            # print(\"algorithm_id:\", algorithm_id) \n",
    "\n",
    "        # store algorithm_id\n",
    "        tool_info['algorithm_id'] = algorithm_id\n",
    "        tool_info['python_code_snippet'] = python_code_snippet\n",
    "\n",
    "        paremeters_section = soup.find('section', id='parameters')\n",
    "        if paremeters_section:\n",
    "            basic_parameters_section = soup.find('section', id='basic-parameters')\n",
    "            advanced_parameters_section = soup.find('section', id='advanced-parameters')\n",
    "            outputs_section = soup.find('section', id='outputs') \n",
    "            \n",
    "            basic_parameters = extract_table(basic_parameters_section) if basic_parameters_section else []\n",
    "            advanced_parameters = extract_table(advanced_parameters_section) if advanced_parameters_section else []\n",
    "            outputs = extract_table(outputs_section) if outputs_section else []\n",
    "\n",
    "            tool_info['basic_parameters'] = basic_parameters\n",
    "            tool_info['advanced_parameters'] = advanced_parameters\n",
    "            tool_info['outputs'] = outputs\n",
    "\n",
    "        # print(tool_info)\n",
    "        print(\"Tool description:\", tool_info['brief_description'])  \n",
    "        return tool_info\n",
    "    else:\n",
    "        # print(\"No h2 found in this section.\")\n",
    "        pass\n",
    "        \n",
    "    return tool_info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f4d94f98-a2be-4eff-a167-4d6d7fa4fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "92adc388-d95e-4e4f-b053-5e87e0c616ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: 28.1.15.1.Cell stack percent rank from value\n",
      "python_code_section: <section id=\"python-code\">\n",
      "<h3>Python code<a class=\"headerlink\" href=\"#python-code\" title=\"Link to this heading\"></a></h3>\n",
      "<p><strong>Algorithm ID</strong>: <code class=\"docutils literal notranslate\"><span class=\"pre\">native:cellstackpercentrankfromvalue</span></code></p>\n",
      "<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">processing</span>\n",
      "<span class=\"n\">processing</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"s2\">\"algorithm_id\"</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"n\">parameter_dictionary</span><span class=\"p\">})</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "<p>The <em>algorithm id</em> is displayed when you hover over the algorithm in\n",
      "the Processing Toolbox.\n",
      "The <em>parameter dictionary</em> provides the parameter NAMEs and values.\n",
      "See <a class=\"reference internal\" href=\"../../processing/console.html#processing-console\"><span class=\"std std-ref\">Using processing algorithms from the console</span></a> for details on how to run processing algorithms\n",
      "from the Python console.</p>\n",
      "</section>\n",
      "Tool description: \n",
      "Tool: 28.1.15.1.Cell stack percent rank from value\n",
      "python_code_section: <section id=\"python-code\">\n",
      "<h3>Python code<a class=\"headerlink\" href=\"#python-code\" title=\"Link to this heading\"></a></h3>\n",
      "<p><strong>Algorithm ID</strong>: <code class=\"docutils literal notranslate\"><span class=\"pre\">native:cellstackpercentrankfromvalue</span></code></p>\n",
      "<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">processing</span>\n",
      "<span class=\"n\">processing</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"s2\">\"algorithm_id\"</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"n\">parameter_dictionary</span><span class=\"p\">})</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "<p>The <em>algorithm id</em> is displayed when you hover over the algorithm in\n",
      "the Processing Toolbox.\n",
      "The <em>parameter dictionary</em> provides the parameter NAMEs and values.\n",
      "See <a class=\"reference internal\" href=\"../../processing/console.html#processing-console\"><span class=\"std std-ref\">Using processing algorithms from the console</span></a> for details on how to run processing algorithms\n",
      "from the Python console.</p>\n",
      "</section>\n",
      "Tool description: \n",
      "Tool: 28.1.15.1.Cell stack percent rank from value\n",
      "python_code_section: <section id=\"python-code\">\n",
      "<h3>Python code<a class=\"headerlink\" href=\"#python-code\" title=\"Link to this heading\"></a></h3>\n",
      "<p><strong>Algorithm ID</strong>: <code class=\"docutils literal notranslate\"><span class=\"pre\">native:cellstackpercentrankfromvalue</span></code></p>\n",
      "<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">processing</span>\n",
      "<span class=\"n\">processing</span><span class=\"o\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"s2\">\"algorithm_id\"</span><span class=\"p\">,</span> <span class=\"p\">{</span><span class=\"n\">parameter_dictionary</span><span class=\"p\">})</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "<p>The <em>algorithm id</em> is displayed when you hover over the algorithm in\n",
      "the Processing Toolbox.\n",
      "The <em>parameter dictionary</em> provides the parameter NAMEs and values.\n",
      "See <a class=\"reference internal\" href=\"../../processing/console.html#processing-console\"><span class=\"std std-ref\">Using processing algorithms from the console</span></a> for details on how to run processing algorithms\n",
      "from the Python console.</p>\n",
      "</section>\n",
      "Tool description: Calculates the cell-wise percentrank value of a stack of rasters based on a single input value and writes them to an output raster.\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.2.Cell stack percentile\n",
      "python_code_section: None\n",
      "Tool description: Calculates the cell-wise percentile value of a stack of rasters and writes the results to an output raster. The percentile to return is determined by the percentile input value (ranges between 0 and 1). At each cell location, the specified percentile is obtained using the respective value from the stack of all overlaid and sorted cell values of the input rasters.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.3.Cell stack percentrank from raster layer\n",
      "python_code_section: None\n",
      "Tool description: Calculates the cell-wise percentrank value of a stack of rasters based on an input value raster and writes them to an output raster.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.4.Cell statistics\n",
      "python_code_section: None\n",
      "Tool description: Computes per-cell statistics based on input raster layers and for each cell writes the resulting statistics to an output raster. At each cell location, the output value is defined as a function of all overlaid cell values of the input rasters.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.5.Equal to frequency\n",
      "python_code_section: None\n",
      "Tool description: Evaluates on a cell-by-cell basis the frequency (number of times) the values of an input stack of rasters are equal to the value of a value layer. The output raster extent and resolution are defined by the input raster layer and is always of Int32 type.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.6.Fuzzify raster (gaussian membership)\n",
      "python_code_section: None\n",
      "Tool description: Transforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Gaussian membership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership of the defined fuzzy set, whereas a value of 1 means full membership. The gaussian membership function is defined as , where f1 is the spread and f2 the midpoint.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.7.Fuzzify raster (large membership)\n",
      "python_code_section: None\n",
      "Tool description: Transforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Large membership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership of the defined fuzzy set, whereas a value of 1 means full membership. The large membership function is defined as , where f1 is the spread and f2 the midpoint.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.8.Fuzzify raster (linear membership)\n",
      "python_code_section: None\n",
      "Tool description: Transforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Linear membership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership of the defined fuzzy set, whereas a value of 1 means full membership. The linear function is defined as , where a is the low bound and b the high bound. This equation assigns membership values using a linear transformation for pixel values between the low and high bounds. Pixels values smaller than the low bound are given 0 membership whereas pixel values greater than the high bound are given 1 membership.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.9.Fuzzify raster (near membership)\n",
      "python_code_section: None\n",
      "Tool description: Transforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Near membership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership of the defined fuzzy set, whereas a value of 1 means full membership. The near membership function is defined as , where f1 is the spread and f2 the midpoint.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.10.Fuzzify raster (power membership)\n",
      "python_code_section: None\n",
      "Tool description: Transforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Power membership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership of the defined fuzzy set, whereas a value of 1 means full membership. The power function is defined as , where a is the low bound, b is the high bound, and f1 the exponent. This equation assigns membership values using the power transformation for pixel values between the low and high bounds. Pixels values smaller than the low bound are given 0 membership whereas pixel values greater than the high bound are given 1 membership.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.11.Fuzzify raster (small membership)\n",
      "python_code_section: None\n",
      "Tool description: Transforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Small membership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership of the defined fuzzy set, whereas a value of 1 means full membership. The small membership function is defined as , where f1 is the spread and f2 the midpoint.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.12.Greater than frequency\n",
      "python_code_section: None\n",
      "Tool description: Evaluates on a cell-by-cell basis the frequency (number of times) the values of an input stack of rasters are equal to the value of a value raster. The output raster extent and resolution is defined by the input raster layer and is always of Int32 type.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.13.Highest position in raster stack\n",
      "python_code_section: None\n",
      "Tool description: Evaluates on a cell-by-cell basis the position of the raster with the highest value in a stack of rasters. Position counts start with 1 and range to the total number of input rasters. The order of the input rasters is relevant for the algorithm. If multiple rasters feature the highest value, the first raster will be used for the position value.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.14.Less than frequency\n",
      "python_code_section: None\n",
      "Tool description: Evaluates on a cell-by-cell basis the frequency (number of times) the values of an input stack of rasters are less than the value of a value raster. The output raster extent and resolution is defined by the input raster layer and is always of Int32 type.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.15.Lowest position in raster stack\n",
      "python_code_section: None\n",
      "Tool description: Evaluates on a cell-by-cell basis the position of the raster with the lowest value in a stack of rasters. Position counts start with 1 and range to the total number of input rasters. The order of the input rasters is relevant for the algorithm. If multiple rasters feature the lowest value, the first raster will be used for the position value.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.16.Raster boolean AND\n",
      "python_code_section: None\n",
      "Tool description: Calculates the boolean AND for a set of input rasters. If all of the input rasters have a non-zero value for a pixel, that pixel will be set to 1 in the output raster. If any of the input rasters have 0 values for the pixel it will be set to 0 in the output raster.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.17.Raster boolean OR\n",
      "python_code_section: None\n",
      "Tool description: Calculates the boolean OR for a set of input rasters. If all of the input rasters have a zero value for a pixel, that pixel will be set to 0 in the output raster. If any of the input rasters have 1 values for the pixel it will be set to 1 in the output raster.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.18.Raster calculator\n",
      "python_code_section: None\n",
      "Tool description: Performs algebraic operations using raster layers.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.19.Raster calculator (virtual)\n",
      "python_code_section: None\n",
      "Tool description: Performs algebraic operations using raster layers and generates in-memory result.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.20.Raster layer properties\n",
      "python_code_section: None\n",
      "Tool description: Returns basic properties of the given raster layer, including the extent, size in pixels and dimensions of pixels (in map units), number of bands, and NoData value.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.21.Raster layer statistics\n",
      "python_code_section: None\n",
      "Tool description: Calculates basic statistics from the values in a given band of the raster layer. The output is loaded in the Processing ► Results viewer menu.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.22.Raster layer unique values report\n",
      "python_code_section: None\n",
      "Tool description: Returns the count and area of each unique value in a given raster layer. The calculation of the area is done in the area unit of the layer’s CRS.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.23.Raster layer zonal statistics\n",
      "python_code_section: None\n",
      "Tool description: Calculates statistics for a raster layer’s values, categorized by zones defined in another raster layer.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.24.Raster surface volume\n",
      "python_code_section: None\n",
      "Tool description: Calculates the volume under a raster surface relative to a given base level. This is mainly useful for Digital Elevation Models (DEM).\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.25.Reclassify by layer\n",
      "python_code_section: None\n",
      "Tool description: Reclassifies a raster band by assigning new class values based on the ranges specified in a vector table.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.26.Reclassify by table\n",
      "python_code_section: None\n",
      "Tool description: Reclassifies a raster band by assigning new class values based on the ranges specified in a fixed table.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.27.Rescale raster\n",
      "python_code_section: None\n",
      "Tool description: Rescales raster layer to a new value range, while preserving the shape (distribution) of the raster’s histogram (pixel values). Input values are mapped using a linear interpolation from the source raster’s minimum and maximum pixel values to the destination minimum and miximum pixel range.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.28.Round raster\n",
      "python_code_section: None\n",
      "Tool description: Rounds the cell values of a raster dataset according to the specified number of decimals.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.29.Sample raster values\n",
      "python_code_section: None\n",
      "Tool description: Extracts raster values at the point locations. If the raster layer is multiband, each band is sampled.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.30.Zonal histogram\n",
      "python_code_section: None\n",
      "Tool description: Appends fields representing counts of each unique value from a raster layer contained within polygon features.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "Tool: 28.1.15.31.Zonal statistics\n",
      "python_code_section: None\n",
      "Tool description: Calculates statistics of a raster layer for each feature of an overlapping polygon vector layer.\n",
      "'NoneType' object has no attribute 'replace'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n",
      "'algorithm_id'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = r'D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\QGIS_plugin\\toml'\n",
    "for section in sections:\n",
    "    try:\n",
    "        tool_info = extract_tool_info(section)    \n",
    "        tool_name = tool_info['algorithm_id'].replace(\":\", \"_\")\n",
    "        # print(\"tool_name:\", tool_name)\n",
    "        fname = os.path.join(save_dir, f\"{tool_name}.toml\")\n",
    "        toml_str = make_TOML_file(tool_info, fname)\n",
    "         \n",
    "        count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(e)\n",
    "\n",
    "    if count > 15: \n",
    "        break\n",
    "\n",
    "toml_str\n",
    "tool_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4964870c-6f22-424f-9fcd-78173826fa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is line one.\n",
      "This is line two.\n",
      "This is line three.\n",
      "\"\"\"\n",
      "This is line one.\n",
      "This is line two.\n",
      "This is line three.\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "def convert_to_triple_quoted_string(input_string):\n",
    "    \"\"\"\n",
    "    Converts a Python multiline string with newline characters into\n",
    "    a triple-quoted multiline string.\n",
    "    \n",
    "    Parameters:\n",
    "    input_string (str): The input string containing newline characters.\n",
    "    \n",
    "    Returns:\n",
    "    str: A string enclosed in triple quotes.\n",
    "    \"\"\"\n",
    "    # Split the string by newline characters to maintain structure\n",
    "    lines = input_string.splitlines()\n",
    "\n",
    "    # Join the lines into a single string, separated by newlines\n",
    "    formatted_string = \"\\n\".join(lines)\n",
    "    print(formatted_string)\n",
    "\n",
    "    # Return the string enclosed in triple quotes\n",
    "    triple_quoted_string = '\"\"\"\\n' + formatted_string + '\\n\"\"\"'\n",
    "\n",
    "    return triple_quoted_string\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_string = \"This is line one.\\nThis is line two.\\nThis is line three.\"\n",
    "triple_quoted = convert_to_triple_quoted_string(input_string)\n",
    "print(triple_quoted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd81ecd-4dcb-43be-b48f-77af796849d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "\n",
    "# Define the multiline string using raw string or triple quotes\n",
    "data = {\n",
    "    \"parameters\": \"\"\"input=name[,name,...][required]\n",
    "    Name of input raster map\n",
    "output=name[required]\n",
    "    Name for output raster map\"\"\"\n",
    "}\n",
    "\n",
    "# Dump the data into a TOML file\n",
    "with open('output.toml', 'w') as toml_file:\n",
    "    toml.dump(data, toml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8725eba3-e0fb-49b1-98a1-3ff61b048dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tomlkit\n",
      "  Obtaining dependency information for tomlkit from https://files.pythonhosted.org/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl.metadata\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: tomlkit\n",
      "Successfully installed tomlkit-0.13.2\n"
     ]
    }
   ],
   "source": [
    "! pip install tomlkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191eb89b-02f0-4e21-bb12-4ca599537adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomlkit\n",
    "\n",
    "# Define the document using tomlkit\n",
    "doc = tomlkit.document()\n",
    "\n",
    "# Add a multiline string to the document\n",
    "multiline_string = '''input=name[,name,...][required]\n",
    "    Name of input raster map\n",
    "output=name[required]\n",
    "    Name for output raster map'''\n",
    "\n",
    "doc['parameters'] = multiline_string\n",
    "\n",
    "# Write the document to a TOML file\n",
    "with open('output.toml', 'w') as toml_file:\n",
    "    tomlkit.dump(doc, toml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5f7cbd-6ecc-4251-9c4a-87c65bf4d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomlkit\n",
    "\n",
    "# Read the TOML file with the \"\\n\" escape sequences\n",
    "with open('output.toml', 'r') as f:\n",
    "    data = tomlkit.parse(f.read())\n",
    "\n",
    "# Get the string value stored under 'parameters'\n",
    "parameters_value = data['parameters']\n",
    "\n",
    "# Replace the \"\\n\" escape characters with actual newlines\n",
    "restored_value = parameters_value.replace('\\\\n', '\\n')\n",
    "\n",
    "# Update the parameters value to be a proper multiline string\n",
    "data['parameters'] = tomlkit.string(restored_value)\n",
    "\n",
    "# Write the modified content back to a new TOML file with proper multiline formatting\n",
    "with open('output2.toml', 'w') as f:\n",
    "    tomlkit.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_geo",
   "language": "python",
   "name": "llm_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
